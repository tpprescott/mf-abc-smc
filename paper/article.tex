\documentclass[12pt, onecolumn]{article}

\usepackage[margin=3cm]{geometry}
%\usepackage[poorman]{fourier}
\usepackage{amsthm, amssymb, amsmath}
\usepackage{algorithm, algorithmic}
\usepackage{parskip, setspace}
\usepackage{cleveref}
\usepackage{graphicx, subcaption}
\usepackage{url}

\graphicspath{{figs/out/png/}}

\onehalfspacing
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=\parskip \thm@postskip=0pt
}
\makeatother

\newcommand{\obs}[1]{#1_{\mathrm{obs}}}
\newcommand{\tp}[1]{#1_{\mathrm{tp}}}
\newcommand{\fp}[1]{#1_{\mathrm{fp}}}
\newcommand{\fn}[1]{#1_{\mathrm{fn}}}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{note}[theorem]{Note}

\begin{document}

\title{Multifidelity Approximate Bayesian Computation with Sequential Monte Carlo Parameter Sampling}
\author{Thomas P. Prescott ~\quad{} Ruth E. Baker}
\date{January 2020}
\maketitle{}

\begin{abstract}
Multifidelity approximate Bayesian computation (MF-ABC) is a likelihood-free technique for parameter inference that exploits model approximations to significantly increase the speed of ABC algorithms~(Prescott and Baker, 2020).
Previous work has considered MF-ABC only in the context of rejection sampling, which does not explore parameter space particularly efficiently.
In this work, we integrate the multifidelity approach with the ABC sequential Monte Carlo (ABC-SMC) algorithm into a new MF-ABC-SMC algorithm.
We show that the improvements generated by each of ABC-SMC and MF-ABC to the efficiency of generating Monte Carlo samples and estimates from the ABC posterior are amplified when the two techniques are used together.
\end{abstract}

\section{Introduction}
\label{s:Intro}

An important goal of the mathematical modelling of a physical system is to be able to make quantitative predictions about its behaviour.
In order to make accurate predictions, the parameters of the mathematical model need to be calibrated against experimental data.
Bayesian inference is a widely-used approach to model calibration that seeks to unify the information from observations with prior knowledge about the parameters to form a posterior distribution on parameter space~\cite{Beaumont2010,Hines2015,Schnoerr2017}.
This approach is based on Bayes' Theorem, whereby the posterior distribution is proportional to the product of the prior distribution and the likelihood of the data under the model.

However, in many practical settings, the model is often too complicated for the likelihood of the data to be calculated, making the posterior distribution unavailable.
In this case, likelihood-free methods for Bayesian parameter inference become a useful option.
Specifically, approximate Bayesian computation (ABC) is a class of such likelihood-free methods~\cite{Sisson2018,Sunnaker2013}.
Rather than calculating the likelihood of the observed data for a given parameter value, it is estimated. 
The model is simulated under a particular parameter value, and the simulated output is then compared with the observed data.
If the simulation and observations are suitably close (according to a predetermined metric and threshold~\cite{Fearnhead2012,Harrison2017a}) then, in the classical rejection sampling approach, the likelihood is approximated as $1$.
Otherwise, the likelihood is approximated as $0$.
This binary approximation is usually interpreted as an acceptance or a rejection of the parameter value input into the simulation.
Using this approach, a weighted Monte Carlo sample from an approximated posterior can be built by repeatedly proposing parameters from the prior distribution, simulating the model with each parameter, and calculating the binary weight.

One widely-acknowledged weakness of the ABC approach is its heavy reliance on repeated simulation.
There has been a significant amount of work dedicated to overcoming this reliance by exploiting methods for intelligent exploration of parameter space in order to reduce the number of simulations in areas of low likelihood~\cite{Sisson2018}.
For example, the parameters to be input into the simulation can instead be proposed from a importance distribution, rather than the prior, which we aim to construct in order to improve the algorithm's performance.
One successful approach to importance sampling is known as Sequential Monte Carlo ABC (ABC-SMC), which aims to build consecutive samples using parameter proposals taken from progressively closer approximations to the posterior, parameterised by decreasing ABC thresholds~\cite{Toni2009}.
Research in this area has considered how to choose the sequence of decreasing thresholds and distance metrics~\cite{DelMoral2012,Prangle2017}, and how best to evolve the parameters from one approximation to produce parameter proposals for the next~\cite{Alsing2018,Beaumont2009,Filippi2013}.

Another proposed strategy for overcoming the simulation bottleneck is the multifidelity ABC (MF-ABC) approach~\cite{Prescott2020}.
This approach assumes that, in addition to the model under investigation (termed the \emph{high-fidelity} model), there also exists a \emph{low-fidelity} model, depending on the same parameters, that is significantly faster to simulate, usually at the cost of being less accurate~\cite{Peherstorfer2018}.
The multifidelity approach to parameter inference uses simulations from both the low-fidelity model and high-fidelity model to approximate the likelihood.
The high-fidelity model is simulated as little as possible, to reduce the simulation bottleneck, but just enough to ensure that the resulting posterior estimate is suitably accurate.
Other approaches that can be interpreted in the multifidelity framework include lazy ABC~\cite{Prangle2016}, delayed acceptance ABC~\cite{Everitt2017} and early rejection~\cite{Picchini2016}.
In each of these, low-fidelity simulations are sometimes used to reject parameters before completing a high-fidelity simulation.
Importantly, the more general MF-ABC framework in \cite{Prescott2020} allows for early acceptance as well as early rejection.

A key observation that can be made about these two techniques for improving ABC performance is that they are orthogonal, in the sense that they improve different aspects of the ABC approach.
ABC-SMC considers only improving the method for proposing parameters to use in simulations and does not directly affect the binary estimate of the likelihood.
In contrast, MF-ABC makes no change to the parameter proposals, but instead directly alters the method used to estimate the likelihood by using a combination of both low-fidelity and high-fidelity model simulations.
The complementarity of these two approaches has previously been shown in the specific context of combining delayed acceptance with SMC~\cite{Everitt2017}.
Thus, combining the general multifidelity framework of~\cite{Prescott2020} with SMC should therefore yield significant speed-up over existing methods.


\subsection{Outline}
\label{s:Outline}
In this paper we bring together these two orthogonal approaches to speeding up ABC algorithms.
We will introduce a combined multifidelity sequential Monte Carlo ABC algorithm (MF-ABC-SMC).
\Cref{s:Background} formulates the existing ABC algorithms briefly described above, and the techniques we can use to quantify their performance.
We then show how the techniques can be combined in \Cref{s:MF-ABC-SMC}, identifying three stages.
First, in \Cref{s:MF-ABC-IS}, we consider how to use an importance distribution for parameter proposals and appropriately reweight the multifidelity approximation of the likelihood.
Second, in \Cref{s:MF-ABC-SIS}, we follow the ABC-SMC technique and demonstrate how to construct an importance distribution from a Monte Carlo sample built using MF-ABC.
Third, \Cref{s:eta} shows that the SMC framework also allows us to tune the multifidelity algorithm to optimise its performance.
\Cref{s:MF-ABC-SMC} then concludes by introducing the MF-ABC-SMC algorithm. 
This new algorithm is applied in \Cref{s:Example} to a heterogeneous network of Kuramoto oscillators in a hierarchical Bayes parameter estimation task, to produce low-variance ABC posterior estimates significantly faster than the classical ABC-SMC approach.
Finally, in \Cref{s:Discussion}, we discuss some important open questions for further optimising the MF-ABC-SMC algorithm.

\section{Theoretical background}
\label{s:Background}

Assume that the model we are seeking to calibrate is a map (usually stochastic) from parameters $\theta$, taking values in a parameter space $\Theta$, to an output $y$, taking values in data space $\mathcal Y$.
We denote this map as a conditional density $f(\cdot~|~\theta)$ on $\mathcal Y$, and term the drawing of $y \sim f(\cdot~|~\theta)$ as simulating the model, with $y$ termed a simulation.
For Bayesian inference, we furthermore assume the existence of a prior distribution $\pi(\cdot)$ on $\Theta$, and of the observed data $\obs y \in \mathcal Y$ that will be used to calibrate the model.
The model induces the likelihood of the observed data, written $f(\obs y~|~\theta)$, which is a function of $\theta$.
As described previously, the goal of Bayesian inference is to infer the posterior distribution $p(\theta~|~\obs y)$ on $\Theta$, given $\obs y$ and $\pi(\cdot)$.
Bayes' Theorem equates the posterior to the product of likelihood and prior,
\[
p( \theta ~|~ \obs y) = \frac{1}{\zeta} f(\obs y~|~\theta) \pi(\theta),
\]
where the normalisation constant, $\zeta$, ensures that $p(\theta~|~\obs y)$ is a probability density that integrates to unity.

\subsection{Approximate Bayesian computation}
\label{s:ABC-RS}

Often, the model under consideration is sufficiently complicated that the likelihood cannot be calculated, necessitating a likelihood-free approach.
We assume that, while the value of any $f(y ~|~ \theta)$ is not available, we are still able to simulate $y \sim f(\cdot ~|~ \theta)$.
Let $d(y, \obs y)$ denote a metric that quantifies how close any simulation, $y$, is to the observed data, $\obs y$. 
For a positive threshold value $\epsilon > 0$, we can then define a neighbourhood $\Omega_\epsilon(d, \obs y) = \{ y \in \mathcal Y ~|~ d(y, \obs y)<\epsilon \}$ of model simulations that are `close' to the data.
Typically the dataset, $\obs y$, is constant for the parameter estimation task, and the distance metric, $d$, is pre-determined.
Hence we will often drop the $(d, \obs y)$ dependence from our notation and simply write $\Omega_\epsilon$ for the $\epsilon$-neighbourhood of $\obs y$ under the distance function $d$.

For a given positive distance threshold $\epsilon > 0$, ABC replaces the exact likelihood, $f(\obs y~|~\theta)$, with the ABC approximation to the likelihood,
\begin{subequations}
\label{eq:ABC}
\begin{equation}
\label{eq:ABClikelihood}
 f_\epsilon(\obs y~|~\theta) = \mathbb P(y \in \Omega_\epsilon ~|~ \theta) = \int \mathbb I(y \in \Omega_\epsilon) f(y~|~\theta) ~\mathrm dy,
\end{equation}
which is, to leading order for small $\epsilon$, approximately proportional to $f(\obs y~|~\theta)$.
The ABC approximation to the likelihood then induces the ABC posterior,
\begin{equation}
\label{eq:ABCposterior}
 p_{\epsilon}(\theta~|~\obs y) = \frac{1}{Z} ~ f_\epsilon( \obs y ~|~ \theta) \pi(\theta),
\end{equation}
\end{subequations}
where (similarly to $\zeta$ above) the constant $Z$ ensures that the ABC posterior is a probability distribution with unit integral.

The rejection sampling ABC algorithm presented in \Cref{ABC:Rejection} presents a simple method for drawing samples from the ABC posterior, $p_\epsilon(\theta~|~\obs y)$.
A weighted Monte Carlo sample $\left\{ \theta_n, w_n \right\}_{n=1}^N$ is returned.
For each parameter proposal, $\theta_n$, the model is simulated and compared with data, and a binary weight $w_n = w(y_n)$ is assigned. 
The weighting function,
\[
 w(y) = \mathbb I(y \in \Omega_\epsilon),
\]
is the indicator of whether the data, $\obs y$, and simulation, $y$, are close.
For any arbitrary function $F(\cdot)$ defined on the parameter space $\Theta$, this Monte Carlo sample produces an estimator of the expected value of $F(\theta)$ under the ABC approximation to the posterior, such that
\begin{equation}
 \label{eq:estimate}
 \mathbb E_{p_\epsilon}(F(\theta)) \approx \bar F = \frac{\sum_{n=1}^N w_n F(\theta_n)}{\sum_{n=1}^N w_n}.
\end{equation}
For the binary weights $w_n = w(y_n)$, the normalised weighted sum, $\bar F$, is an unbiased estimate of the approximated posterior mean, $\mathbb E_{p_\epsilon}(F(\theta))$.

\begin{algorithm}
\caption{Rejection sampling ABC (ABC-RS)}
\label{ABC:Rejection}
\begin{algorithmic}[1]
\REQUIRE{
Data $\obs y$ and neighbourhood $\Omega_\epsilon$; 
model $f(\cdot~|~\theta)$; 
prior $\pi$; 
sample index $n=0$; 
stopping criterion $S$.
}
\ENSURE{Weighted sample $\left\{ \theta_n, w_n \right\}_{n=1}^{N}$.}
\REPEAT{}
 \STATE{Increment $n \leftarrow n+1$.}
 \STATE{Generate $\theta_n \sim \pi(\cdot)$.}
 \STATE{Simulate $y_n \sim f(\cdot~|~\theta_n)$.}
 \STATE{Set $w_n = \mathbb I \left( y_n \in \Omega_\epsilon \right)$.}
\UNTIL{$S=$ \texttt{true}.}
\end{algorithmic}
\end{algorithm}

The presentation of ABC-RS in \Cref{ABC:Rejection} is slightly modified from its usual description, although the resulting sample is equivalent.
Usually, the values of $\theta_n$ such that $w_n=0$ are considered as being rejected from the sample, and they can be discarded.
The weights of the remaining accepted $\theta_n$ are all equal.
Denoting the set of accepted indices $A = \{ n~:~w_n>0 \}$,
the resulting formulation of the estimator, $\bar F$, in \Cref{eq:estimate} is 
\[
 \mathbb E_{p_\epsilon}(F(\theta)) \approx \bar F = \frac{1}{|A|} \sum_{n \in A} F(\theta_n),
\]
which is clearly the (unweighted) Monte Carlo estimate from the sample of accepted proposals.
However, the weighted formulation adds clarity as we extend the algorithm in the remainder of this paper.

Many presentations of ABC-RS often define the stopping criterion to be when the number of accepted parameter proposals, $|A|$, reaches some predefined value~\cite{Beaumont2010,Sisson2018}.
However, we keep this criterion general, to allow for the algorithm to terminate after (for example) a fixed number of parameter proposals, $N$, or when a fixed budget of total computational time or memory is reached, or any other more complicated combination of such conditions.
Note that ABC-RS is easily parallelised, although care must be taken to ensure that the chosen stopping condition is correctly applied in this case~\cite{Jagiella2017}.

\subsection{Importance sampling}
\label{s:ImportanceSampling}

One widely-acknowledged weakness of rejection sampling ABC is the potential for wasted computational effort. 
Rejection sampling depends on repeated sampling from the prior. 
However, for $p_\epsilon(\theta~|~\obs y)$ to be a good approximation to the likelihood, $p(\theta~|~\obs y)$, we require a relatively small value of $\epsilon$.
This means that, in regions of low likelihood, many simulations will produce $y \notin \Omega_\epsilon$ and so will receive zero weight.
This often leads to poor performance: a large computational burden that produces many rejections.
In this setting, \emph{importance sampling} is one adaptation of \Cref{ABC:Rejection} commonly used to improve its performance.
It works by carrying out fewer simulations in regions of low likelihood~\cite{Sisson2018,Owen2013} by proposing parameters according to an importance distribution defined on $\Theta$.

Suppose that, in addition to the prior density, $\pi(\theta)$, there is a non-negative function $q(\theta) \geq 0$ defined on $\Theta$.
If $q(\theta)>0$ for all $\theta$ in the support of $\pi$, then the probability distribution $\hat q = q(\cdot)/Z_q$, with the normalisation constant $Z_q = \int_\Theta q(\theta) ~\mathrm d\theta$, is termed an importance distribution.
Note that we do not assume that we can calculate $\hat q(\theta)$, because we do not necessarily have access to the normalisation constant $Z_q$.
However, we assume that we can sample $\theta \sim \hat q(\cdot)$ from the importance distribution.

\Cref{ABC:Importance} (ABC-IS) is a generalisation of \Cref{ABC:Rejection} (ABC-RS) that again produces a weighted sample $\{ \theta_n, w_n \}_{n=1}^N$ from the ABC posterior $p_\epsilon(\theta~|~\obs y)$.
The generalisation consists of generating $\theta_n$ from the importance distribution, $\hat q(\cdot)$, rather than from the prior, $\pi(\cdot)$, and then setting $w_n = w(\theta_n, y_n)$ for the redefined weighting function
\begin{equation}
 \label{eq:ImportanceWeight}
 w(\theta, y) = \left[ \pi(\theta) \big/ q(\theta) \right] \cdot \mathbb I(y \in \Omega_\epsilon),
\end{equation}
where the indicator function is scaled by the ratio of $\pi$ to the unnormalised function, $q$, defining the importance distribution.
Clearly, if we choose the importance distribution $\hat q = \pi$ equal to the prior, then \Cref{ABC:Importance} is exactly the rejection sampling approach of \Cref{ABC:Rejection}.
For general $\hat q$, \Cref{lemma:MC} below shows that the resulting weighted sample is still from the ABC posterior.
In \Cref{s:Performance} we quantify the increase in performance that importance distributions can produce.

\begin{algorithm}
\caption{Importance sampling ABC (ABC-IS)}
\label{ABC:Importance}
\begin{algorithmic}[1]
\REQUIRE{
Data $\obs y$ and neighbourhood $\Omega_\epsilon$; 
model $f(\cdot~|~\theta)$; 
prior $\pi$; 
importance distribution $\hat q$ proportional to $q$; 
sample index $n=0$; 
stopping criterion $S$.
}
\ENSURE{Weighted sample $\left\{ \theta_n, w_n \right\}_{n=1}^{N}$.}
\REPEAT{}
 \STATE{Increment $n \leftarrow n+1$.}
 \STATE{Generate $\theta_n \sim \hat q(\cdot)$.}
 \STATE{Simulate $y_n \sim f(\cdot~|~\theta_n)$.}
 \STATE{Set $w_n = \left[ \pi(\theta_n) \big/ q(\theta_n) \right] \cdot \mathbb I \left( y_n \in \Omega_\epsilon \right) $.}
\UNTIL{$S =$ \texttt{true}.}
\end{algorithmic}
\end{algorithm}

\begin{lemma}
\label{lemma:MC}
Consider the Monte Carlo sample $\{ \theta_n, w_n \}_{n=1}^N$ generated by an ABC algorithm where each $\theta_n \sim \hat q$ is independently generated from the importance distribution, $\hat q$, and each weight, $w_n$, is randomly generated conditionally on $\theta_n$.
Suppose that there exists a positive constant $\lambda$ such that
\begin{equation}
\label{eq:ABCCondition}
\mathbb E(w~|~\theta) \hat q(\theta) = \lambda f_\epsilon(\obs y~|~\theta) \pi(\theta),
\end{equation}
where $f_\epsilon$ is the ABC approximation to the likelihood and where $\pi(\cdot)$ is the prior.
Then, for arbitrary functions $F$ on $\Theta$, the mean squared error (MSE),
\[
\mathbb E\left( \left( \bar F - \mathbb E_{p_\epsilon} \left(F(\theta) \right) \right)^2 \right),
\]
between $\mathbb E_{p_\epsilon}(F(\theta))$ and $\bar F$, defined in \Cref{eq:estimate}, decays as $N \rightarrow \infty$ on the order of $1/N$.
Thus, the Monte Carlo sample is from the ABC posterior $p_\epsilon(\theta~|~\obs y)$.
\end{lemma}
\begin{proof}
For an arbitrary pair $(w, \theta)$ from the Monte Carlo sample, the expected value of $w F(\theta)$ can be conditioned on $\theta$ to give 
\begin{align*}
\mathbb E(w F(\theta)) 
&= \int F(\theta) \mathbb E(w~|~\theta) \hat q(\theta) ~\mathrm d\theta 
\\ 
&= \lambda \int F(\theta) f_\epsilon(\obs y~|~\theta) \pi(\theta) ~\mathrm d\theta 
\\
&= \lambda Z \mathbb E_{p_\epsilon}(F(\theta)).
\end{align*}
For the particular case where $F \equiv 1$, it follows that $\mathbb E(w) = \lambda Z$.

Using the delta method~\cite{Seltman2018}, we can therefore write both the bias and variance of the ratio in \Cref{eq:estimate}, to leading order, as
\begin{subequations}
\label{eq:estimate:MSE}
\begin{align}
\mathrm{Bias}(\bar F) = \mathbb E \left( \bar F \right) - \mathbb E_{p_\epsilon}(F(\theta))
&= 
\frac{1}{N} \frac{\mathbb E \left( w^2 \left[ \mathbb E_{p_\epsilon}(F(\theta)) - F \left(\theta\right) \right] \right)}{\mathbb E(w)^2} + O(1/N^2),
\label{eq:estimate:bias}
\\
\mathrm{Var} \left( \bar F \right)
&=
\frac{1}{N} \frac{\mathbb E \left( w^2 \left[ \mathbb E_{p_\epsilon}(F(\theta)) - F\left(\theta\right) \right]^2 \right) }{\mathbb E(w)^2} + O(1/N^2).
\label{eq:estimate:variance}
\end{align}
\end{subequations}
Using the standard decomposition of the MSE into the sum of the variance and squared bias, it follows that, to leading order, the MSE is dominated by the variance term given in \Cref{eq:estimate:variance} as $N \rightarrow \infty$.
Therefore the estimate in \Cref{eq:estimate} is consistent in the limit of large sample size, with convergence in MSE on the order of $1/N$. 
\end{proof}

\begin{note}
For $w_n = \mathbb I(y_n \in \Omega_\epsilon)$ as used in ABC-RS, it follows from the identity $w^2 = w$ that the bias is zero.
However, for more general weights satisfying \Cref{eq:ABCCondition}, the estimate $\bar F$ in \Cref{eq:estimate} is, in general, a biased estimate of the approximate posterior mean $\mathbb E_{p_\epsilon}(F(\theta))$.
Nevertheless, we neglect the contribution of this bias to the MSE, as it is dominated by the variance.
\end{note}

For the weight function $w(\theta, y)$ in \Cref{eq:ImportanceWeight}, we have $\mathbb E(w~|~\theta) = \pi(\theta) f_\epsilon(\obs y~|~\theta) / q(\theta)$.
Since $\theta \sim \hat q(\theta) = q(\theta)/Z_q$, it follows that \Cref{eq:ABCCondition} is satisfied with $\lambda = 1/Z_q$.
Thus, \Cref{lemma:MC} ensures that the weighted Monte Carlo sample returned by \Cref{ABC:Importance} is from the ABC posterior, $p_\epsilon(\theta~|~\obs y)$.

\subsection{Sequential Monte Carlo (SMC)}
\label{s:SMC}

One way of generating importance distributions is provided by ABC-SMC.
A number of presentations of this technique have been proposed with subtle differences~\cite{Beaumont2009,DelMoral2006,Sisson2007}, but we will focus on the \emph{sequential importance sampling} approach~\cite{Toni2009}. 
Let $\epsilon_1 > \epsilon$ be a larger value for the ABC threshold, which induces a larger neighbourhood $\Omega_{\epsilon_1} \supseteq \Omega_\epsilon$ around $\obs y$.
This in turn induces a ``more approximate'' ABC approximation to the likelihood, $f_{\epsilon_1}(\obs y~|~\theta)$, and hence a ``more approximate'' ABC posterior, $p_{\epsilon_1}(\theta~|~\obs y)$.

The ABC-SMC approach proceeds by constructing an importance distribution out of a sample built from $p_{\epsilon_1}$.
This importance distribution is then used to construct the sample from $p_\epsilon$.
By construction, the importance distribution will be more likely than the prior to propose parameters in regions of parameter space where the likelihood is greater than the prior.
Hence, more simulations will result in positive weights, compared to using the prior to propose parameters.
The approach naturally extends to $T \geq 2$ generations, by defining a sequence of thresholds $\epsilon_1 > \dots > \epsilon_T = \epsilon$ and constructing a sequence of importance distributions that evolve towards the target posterior $p_\epsilon$.

\Cref{ABC:SMC} presents the sequential importance sampling approach to ABC-SMC.
Each Monte Carlo sample $\{ \theta_n^{(t)}, w_n^{(t)} \}$ built at generation $t$ is used to construct an importance distribution $\hat q_{t+1}$, defined in \Cref{eq:importance}, that is used to generate the next generation's Monte Carlo sample.
The final sample, $\{ \theta_n^{(T)}, w_n^{(T)} \}$, is produced by \Cref{ABC:Importance} using importance distribution $\hat q_T$ and threshold $\epsilon_T = \epsilon$.
By \Cref{lemma:MC}, it is therefore a Monte Carlo sample from the target ABC posterior, $p_\epsilon(\theta~|~\obs y)$. 

\begin{algorithm}
\caption{Sequential Monte Carlo ABC (ABC-SMC)}
\label{ABC:SMC}
\begin{algorithmic}[1]
\REQUIRE{
Data $\obs y$; 
sequence of nested neighbourhoods $\Omega_{\epsilon_T} \subseteq \Omega_{\epsilon_{T-1}} \subseteq \cdots \subseteq \Omega_{\epsilon_1}$ for $0 < \epsilon = \epsilon_T < \epsilon_{T-1} < \dots < \epsilon_1$; 
prior $\pi$; 
perturbation kernels $K_t(\cdot~|~\theta)$; 
initial importance distribution $\hat q_1$ (often set to $\pi$); 
model $f(\cdot~|~\theta)$; 
stopping conditions $S_1, S_2, \dots, S_T$.}
\ENSURE{Weighted sample $\left\{ \theta_n^{(T)}, w_n^{(T)} \right\}_{n=1}^{N_T}$.}
\FOR{$t=1, \dots, T-1$}
\STATE{Produce $\{ \theta_n^{(t)}, w_n^{(t)}\}_{n=1}^{N_t}$ using \Cref{ABC:Importance} (ABC-IS) with importance distribution $\hat q_t$, neighbourhood $\Omega_{\epsilon_t}$, and stopping condition $S_t$.}
\STATE{Define the next importance distribution, $\hat q_{t+1}$, proportional to 
\begin{equation}
\label{eq:importance}
q_{t+1}( \theta ) = \begin{cases}
                    	\sum_{n=1}^{N_t} w_n^{(t)} K_t( \theta ~|~\theta_n^{(t)}) \bigg/ \sum_{m=1}^{N_t} w_m^{(t)} & \pi(\theta)>0 , \\
                     0 &\text{else.}
                    \end{cases}
\end{equation}}
\ENDFOR{}
\STATE{Produce $\left\{ \theta_n^{(T)}, w_n^{(T)} \right\}_{n=1}^{N_T}$ using \Cref{ABC:Importance} (ABC-IS) with importance distribution $\hat q_T$, neighbourhood $\Omega_{\epsilon_T} = \Omega_\epsilon$, and stopping condition $S_T$.}
\end{algorithmic}
\end{algorithm}

One important aspect of this algorithm is the method for sampling from each importance distribution $\hat q_t$, with density proportional to $q_t$, as defined in \Cref{eq:importance}.
The following procedure generates $\theta^\star \sim \hat q_{t+1}(\cdot)$:
\begin{enumerate}
\item Choose a parameter $\theta^{\star\star}$ from the set $\{ \theta_n^{(t)} \}_{n=1}^{N_t}$, with probabilities proportional to the weights $\{ w_n^{(t)} \}_{n=1}^{N_t}$.
\item Perturb the parameter according to a perturbation kernel $K_t$, producing $\theta^{\star} \sim K_{t}(\cdot~|~\theta^{\star\star})$.
\item If $\pi(\theta)>0$, then return $\theta^{\star}$; else return to 1.
\end{enumerate}
Note that the ABC-SMC algorithm requires the specification of a threshold sequence $\epsilon_t$, the stopping conditions $S_t$, and the perturbation kernels $K_t(\cdot~|~\theta)$ for $t=1,\dots,T$~\cite{Sisson2018}.
We will not re-examine these aspects of ABC-SMC in detail in this paper, and will implement ABC-SMC using established techniques to select $\epsilon_t$, $S_t$ and $K_t$~\cite{Toni2009,DelMoral2012,Beaumont2009,Filippi2013}.

\subsection{Multifidelity ABC}
\label{s:MFABC}
Importance sampling and SMC approaches can improve the performance of ABC by exploring parameter space more efficiently, so that simulation time is not wasted in regions of low likelihood.
An orthogonal approach to improving ABC is to attempt to avoid computationally expensive simulations, where possible, by relying on the \emph{multifidelity} framework~\cite{Prescott2020}.
We term the model of interest, $f(\cdot~|~\theta)$, which maps parameter space $\Theta$ to an output space $\mathcal Y$, as the high-fidelity model.
We now assume that, in addition, there is a low-fidelity (i.e. approximate) model, $\tilde f(\cdot~|~\theta)$, of the same physical system with the same parameter space $\Theta$.
The simulations of this model are denoted $\tilde y \sim \tilde f(\cdot~|~\theta)$, taking values in the output space $\tilde{\mathcal Y}$, which may differ from $\mathcal Y$.
Importantly, we assume that the low-fidelity model is computationally cheaper, in the sense that simulations $\tilde y \sim \tilde f(\cdot~|~\theta)$ of the low-fidelity model incur less computational burden than simulations $y \sim f(\cdot~|~\theta)$ of the high-fidelity model.

We can also assume that the experimental observations $\obs y \in \mathcal Y$ can be mapped to the new data space, giving $\obs{\tilde y} \in \tilde{\mathcal Y}$.
Similarly, we define an associated region,
\[
 \tilde \Omega_{\epsilon} = \tilde \Omega_{\epsilon} (\obs{\tilde y}, \tilde d) = \{ \tilde y \in \tilde{\mathcal Y} ~|~ \tilde d(\tilde y,\obs{\tilde y}) < \tilde \epsilon \},
\]
that is the $\tilde \epsilon$-neighbourhood of the observed data, $\obs{\tilde y}$, as a subset of the output space $\tilde{\mathcal Y}$, defined under the distance metric $\tilde d$.
However, in the interests of clarity, we will assume for the remainder of this article that the output spaces of each model fidelity are such that $\tilde{\mathcal Y} = \mathcal Y$.
Similarly, we assume that the observed data are such that $\obs{\tilde y} = \obs y$, the distance metrics are such that $\tilde d = d$, and the ABC thresholds are such that $\tilde \epsilon = \epsilon$, so that $\tilde \Omega_{\tilde \epsilon} = \Omega_\epsilon$.

In general, the models $f(\cdot~|~\theta)$ and $\tilde f(\cdot~|~\theta)$ can be simulated independently for a given $\theta$.
Then, if the low-fidelity model is a good approximation to the high-fidelity model, the outputs $y$ and $\tilde y$ will be near, in some sense.
However, we will also allow for \emph{coupling} between the two models, 
by which we mean that a simulation from the high-fidelity model can be conditioned on a low-fidelity simulation, $\tilde y \sim \tilde f(\cdot~|~\theta)$~\cite{Giles2008}.
The coupling approach requires us to specify the \emph{coupled} high-fidelity model, with probability distribution $f(\cdot~|~\tilde y, \theta)$.
The key condition for a valid coupled high-fidelity model is that
\begin{equation}
\label{eq:coupling}
 \int_{\tilde{\mathcal{Y}}} f(y ~|~ \tilde y, \theta) \tilde f(\tilde y~|~\theta) ~\mathrm d\tilde y = f(y ~|~ \theta).
\end{equation}
The benefit of this approach is that, with a judicious choice of coupling method, a simulation $y \sim f(\cdot~|~\tilde y, \theta)$ from the coupled high-fidelity model is more closely correlated to $\tilde y$ than an independent simulation $y \sim f(\cdot~|~\theta)$ from the original high-fidelity model.
Furthermore, simulations of $y \sim f(\cdot~|~\tilde y, \theta)$ may be less computationally burdensome than simulations of $y \sim f(\cdot~|~\theta)$.

As an example, suppose the high-fidelity model is a Markovian stochastic dynamical system on the time horizon $t \in [0,T]$, and that the low-fidelity model is the same system on $t \in [0,\tau]$ for $\tau<T$~\cite{Prangle2016}.
The low-fidelity and high-fidelity models can clearly be simulated independently on $[0,\tau]$ and $[0,T]$, respectively, and the low-fidelity simulation will, on average, be less computationally expensive than the high-fidelity simulation.
However, suppose we have generated a simulation, $\tilde y(t)$, of the low-fidelity model, which is a trajectory over $t \in [0,\tau]$.
In this case, a natural coupling is to deterministically assign $y(t)$ to have the same trajectory as $\tilde y(t)$ over $t \in [0, \tau]$, and then complete the simulation for $y(t)$ over $t \in [\tau, T]$ from the initial condition $\tilde y(\tau)$.
The coupled high-fidelity simulation, $y$, generated conditionally on $\tilde y$, incurs further simulation cost beyond that of $\tilde y$, but this is less than that incurred by generating an independent (i.e. uncoupled) high-fidelity simulation.
Many other possible couplings exist for different multifidelity models, often involving shared random noise processes, and methods for coupling are currently an area of active research~\cite{Prescott2020,Croci2018,Lester2018}.

In order to apply the multifidelity framework to ABC parameter inference, recall that each weight, $w_n$, generated by \Cref{ABC:Rejection,ABC:Importance} requires a simulation $y_n \sim f(\cdot~|~\theta_n)$ from the high-fidelity model.
The multifidelity approach defines another weighting function for each Monte Carlo weight $w_n = w(\tilde y_n, u_n, y_n)$, such that
\begin{equation}
w(\tilde y, u, y)
= 
\mathbb I(\tilde y \in \Omega_{\epsilon}) + \frac{\mathbb I(u < \alpha)}{\alpha} \left( \mathbb I(y \in \Omega_{\epsilon}) - \mathbb I(\tilde y \in \Omega_{\epsilon}) \right),
 \label{eq:w_mf}
\end{equation}
where now $y \sim f(\cdot~|~\tilde y, \theta)$ is simulated from the coupled high-fidelity model.
In addition to the multifidelity simulations, this weight incorporates a unit uniform random variable $u$, and a positive \emph{continuation probability} $\alpha = \alpha(\tilde y, \theta) \in (0,1]$.
As with the importance distribution $\hat q$ in \Cref{s:ImportanceSampling}, we assume (for now) that the function $\alpha$ is known.

With an appropriate choice of the order in which the various terms are calculated, the multifidelity weight, $w(\tilde y, u, y)$, will sometimes be computed without simulating $y \sim f(\cdot~|~\tilde y, \theta)$ from the (coupled) high-fidelity model.
First, we simulate $\tilde y \sim \tilde f(\cdot~|~\theta)$ from the low-fidelity model, and calculate the continuation probability $\alpha(\tilde y, \theta)$.
Second, we generate the unit uniform random variable, $u$.
If $u \geq \alpha$ then we can return $w(\tilde y, u, y) = \mathbb I(\tilde y \in \Omega_{\epsilon})$ without simulating from $f$, thereby returning a weight for the lower computational expense of only simulating from $\tilde f$.
\Cref{MFABC:Rejection} is an adaptation of \Cref{ABC:Rejection} that returns a weighted sample $\{ \theta_n, w_n \}_{n=1}^N$ from the ABC posterior $p_\epsilon(\obs y ~|~ \theta)$, with weights calculated using $w$ in \Cref{eq:w_mf}.

\begin{algorithm}
\caption{Rejection sampling multifidelity ABC (MF-ABC-RS)}
\label{MFABC:Rejection}
\begin{algorithmic}[1]
\REQUIRE{
Data $\obs y$ and neighbourhood $\Omega_\epsilon$; 
prior $\pi$; 
models $\tilde f(\cdot~|~\theta)$, $f(\cdot~|~\tilde y, \theta)$; 
continuation probability function $\alpha = \alpha(\tilde y, \theta)$; 
sample index $n=0$; 
stopping condition $S$.
}
\ENSURE{Weighted sample $\{ \theta_n, w_n \}_{n=1}^{N}$.}
\REPEAT{}
 \STATE{Increment $n \leftarrow n+1$.}
 \STATE{Generate $\theta_n \sim \pi(\cdot)$.}
 \STATE{Simulate $\tilde y_n \sim \tilde f(\cdot~|~\theta_n)$.}
 \STATE{Set $w_n = \mathbb I \left( \tilde y_n \in \Omega_{\epsilon} \right)$.}
 \STATE{Generate $u_n \sim \mathrm{Uniform}(0,1)$.}
 \IF{$u_n < \alpha(\tilde y_n, \theta_n)$}
  \STATE{Simulate $y_n \sim f(\cdot ~|~ \tilde y_n, \theta_n)$.}
  \STATE{Update $w_n \leftarrow w_n + \left[ \mathbb I(y \in \Omega_\epsilon) - w_n \right] \big/ \alpha(\tilde y_n, \theta_n)$.}
 \ENDIF{}
\UNTIL{$S =\texttt{true}$.}
\end{algorithmic}
\end{algorithm}

\begin{proposition}
\label{MFABCValidity}
The weighted Monte Carlo sample $\{ \theta_n, w_n\}$ returned by \Cref{MFABC:Rejection} is from the ABC posterior $p_\epsilon(\theta~|~\obs y)$.
\end{proposition}
\begin{proof}
By \Cref{lemma:MC}, we need to show that \Cref{eq:ABCCondition} holds.
Here $\hat q = \pi$ and performing the triple integral in the order $u$, $\tilde y$, then $y$ gives the equality
\begin{align*}
\mathbb E(w(\tilde y, u, y)~|~\theta) 
&= \iiint w(\tilde y, u, y) f(y~|~\tilde y, \theta) \tilde f(\tilde y~|~\theta) ~\mathrm du ~\mathrm d\tilde y ~\mathrm dy 
\\
&= \iint \mathbb I(y \in \Omega_\epsilon) f(y~|~\tilde y, \theta) \tilde f(\tilde y~|~\theta) ~\mathrm d\tilde y ~\mathrm dy
\\
&= \int \mathbb I(y \in \Omega_\epsilon) f(y~|~\theta) ~\mathrm dy
\\
&= f_\epsilon(\obs y~|~\theta).
\end{align*}
Hence \Cref{eq:ABCCondition} holds for $w_n = w(\tilde y_n, u_n, y_n)$ given by \Cref{eq:w_mf}, and the result follows.
\end{proof}

Note that smaller values of the continuation probability, $\alpha$, lead to greater savings in computational burden, since high-fidelity simulations, $y_n$, are generated less often.
However, it is possible to show that this comes at the cost of an increase in the MSE of the estimator, $\bar F \approx \mathbb E_{p_\epsilon}(F(\cdot))$, (as given in \Cref{eq:estimate}) of an arbitrary function $F(\cdot)$ on $\Theta$.
We now describe in more detail the trade-off between reducing the computational burden and increasing the MSE.

\subsection{ABC Performance}
\label{s:Performance}

In \Cref{s:Background} so far, we have summarised previous developments of ABC algorithms that aim to improve performance, but have not yet defined how to quantify this and thereby evaluate the improvements of \Cref{ABC:Importance,ABC:SMC,MFABC:Rejection} over \Cref{ABC:Rejection} (ABC-RS).
In \Cref{lemma:MC} we identified the limiting behaviour of the MSE of weighted Monte Carlo estimates $\bar F$ to be dominated by the estimator variance, given to leading order in \Cref{eq:estimate:variance}.
In the case of ABC-RS, the variance simplifies to
\begin{equation}
\label{eq:ABCRSVariance}
\mathrm{Var} \left( \bar F \right) 
\approx
\frac{\mathrm{Var}_{p_\epsilon} (F(\theta))}{NZ},
\end{equation}
where we recall $Z = \mathbb P(y \in \Omega_\epsilon)$ is the normalisation constant in \Cref{eq:ABCposterior}.
Since the variance term, $\mathrm{Var} \left( \bar F \right)$, dominates the MSE, it follows that, in order to construct a weighted Monte Carlo estimate with a particular value of MSE, we require the number, $N$, of parameter proposals (and thus simulations) to be on the order
\[
N \approx \frac{\mathrm{Var}_{p_\epsilon} (F(\theta)) / \mathrm{MSE} }{Z}.
\]
For small values of $\epsilon$, the constant $Z = \mathbb P(y \in \Omega_\epsilon)$ is also small. 
Hence, the computational burden, if measured by the number of required simulations to achieve a target MSE, may be unreasonably large when $\epsilon$ is small.
% In this example, $Z$ can be thought of as a measure of the efficiency of the algorithm, since it controls how much computation is required to produce a sample to a given MSE.

We can express the computational burden more explicitly in terms of simulation costs.
For concreteness, we define $T_{\mathrm{total}} = \sum_n T_n$ to be the sum of the elapsed times, $T_n = T(w_n)$, taken to calculate each $w_n$ given $\theta_n$.
Then $\mathbb E(T_{\mathrm{total}}) = N \mathbb E(T)$, where the random variable $T$ denotes the time taken to generate a single weight $w$.
Therefore,
\[
\mathbb E(T_{\mathrm{total}}) 
\approx
\frac{\mathrm{Var}_{p_\epsilon} (F(\theta)) / \mathrm{MSE} }{Z / \mathbb E(T)},
\]
gives an estimate of the expected simulation time required to construct a Monte Carlo estimate, $\bar F \approx \mathbb E_{p_\epsilon}(F(\theta))$, using \Cref{ABC:Rejection} (ABC-RS) with a target MSE value.
In this formulation of computational cost, we will interpret the ratio $Z/\mathbb E(T)$ as the theoretical efficiency of \Cref{ABC:Rejection}, according to \Cref{def:efficiency:th} below.

This analysis motivates the following definition of the theoretical efficiency of general ABC algorithms that satisfy the conditions of \Cref{lemma:MC}.
In particular, we no longer assume binary weights $w_n \in \{ 0,1\}$.
The theoretical efficiency quantifies the predicted computational cost of constructing a Monte Carlo estimate to a given variance.

\begin{definition}
\label{def:efficiency:obs}
The \emph{effective sample size}~\cite{Elvira2018} of a weighted Monte Carlo sample $\{ \theta_n, w_n \}$ is 
\[
\mathrm{ESS} = \frac{\left(\sum_n w_n\right)^2}{\sum_n w_n^2}.
\]
The \emph{observed efficiency} of a weighted Monte Carlo sample is
\[
\frac{\mathrm{ESS}}{T_{\mathrm{total}}} = \frac{\left(\sum_n w_n\right)^2}{\left( \sum_n w_n^2 \right) \left( \sum_n T_n \right)},
\]
which is expressed in units of effective samples per time unit.
\end{definition}
\begin{definition}
\label{def:efficiency:th}
The \emph{theoretical efficiency} of an algorithm generating a weighted Monte Carlo sample satisfying the conditions of \Cref{lemma:MC} is
\[
	\psi = \frac{\mathbb E(w)^2}{\mathbb E(w^2) \mathbb E(T)},
\]
which is expressed in units of effective samples per time unit.
\end{definition}

The observed efficiency of any Monte Carlo sample output from an algorithm is itself a Monte Carlo estimate of the theoretical efficiency, $\psi$, of that algorithm.
The theoretical efficiency is closely related to the estimator variance given in \Cref{eq:estimate:variance}, which can be approximated as
\[
\mathrm{Var} \left( \bar F \right) 
\approx
\frac{\mathrm{Var}_{p_\epsilon}(F(\theta))}{N \left( \mathbb E(w)^2 / \mathbb E(w^2) \right) }.
\]
Note that for ABC-RS, where $w_n = \mathbb I(y_n \in \Omega_\epsilon)$ and we propose parameters from the prior (so that $\hat q = \pi$), then we can write the ratio $\mathbb E(w)^2/\mathbb E(w^2) = Z$ to recover \Cref{eq:ABCRSVariance}.
More generally, by following the same arguments as for the ABC-RS case, it follows that the expected computational cost of achieving a specific MSE is approximately
\[
\mathbb E(T_{\mathrm{total}}) \approx \frac{\mathrm{Var}_{p_\epsilon}(F(\theta)) / \mathrm{MSE}}{\psi}.
\]
Thus, as expected, smaller values of the theoretical efficiency, $\psi$, correspond to larger computational cost.

For example, the theoretical efficiency of \Cref{ABC:Rejection} (ABC-RS) is
\[
\psi_{\text{ABC-RS}} = \frac{Z}{\mathbb E_\pi( \mathbb E(T~|~\theta))},
\]
while the theoretical efficiency of \Cref{ABC:Importance} (ABC-IS) is 
\[
\psi_{\text{ABC-IS}} = \frac{Z}{\mathbb E_{p_\epsilon}(\pi/q) \mathbb E_{\hat q}( \mathbb E(T~|~\theta) ) },
\]
where $\mathbb E_{p_\epsilon}(\pi/q)$ is the posterior estimate of the ratio $\pi / q$ of the prior and the unnormalised importance distribution.
Here, $\mathbb E_{\hat q}( \mathbb E(T~|~\theta))$ is the expected simulation time averaged across all parameter proposals from $\hat q$ (and similarly for $\mathbb E_\pi( \mathbb E(T~|~\theta))$ for parameter proposals from $\pi$).
Hence, suppose we have an importance distribution, defined by $q$, such that the theoretical efficiencies satisfy $\psi_{\text{ABC-IS}} > \psi_{\text{ABC-RS}}$.
This occurs for importance distributions such that $\pi/q$ is relatively small in regions of high likelihood, and such that $q$ has relatively low density compared to $\pi$ in regions of parameter space that induce expensive simulations.
Then we would expect to produce samples with higher observed efficiency by using \Cref{ABC:Importance} (ABC-IS) compared to \Cref{ABC:Rejection} (ABC-RS).

By using the theoretical efficiency, $\psi$, as a performance metric in the remainder of this paper, we will quantify the improvement in performance over \Cref{ABC:Rejection,ABC:Importance,ABC:SMC,MFABC:Rejection} that can be achieved by combining multifidelity and SMC techniques.

\section{Multifidelity ABC-SMC}
\label{s:MF-ABC-SMC}
There are two distinct approaches to improving the performance of ABC parameter inference specified in \Cref{s:Background}:
proposing parameters $\theta_n$ from importance distributions (and scaling the weight $w_n$ appropriately), and 
calculating a weight $w_n$ without necessarily having to produce a simulation, $y_n$, from the high-fidelity model.
In this section we present the main contribution of this paper, which is to exploit both of these approaches to further improve the performance of ABC inference, as defined in \Cref{s:Performance}.
We can replicate the procedure of extending \Cref{ABC:Rejection} (ABC-RS) into \Cref{ABC:SMC} (ABC-SMC) in the multifidelity context by: 
(a) defining MF-ABC importance sampling, and 
(b) applying sequential importance sampling for importance distributions defined by consecutive generations of MF-ABC samples.
However, an additional step for ensuring good performance in the multifidelity context is also 
(c) choosing the continuation probabilities for each generation.
In this section, we consider each of these questions in turn.

\subsection{Multifidelity ABC Importance Sampling}
\label{s:MF-ABC-IS}

The basis of ABC-SMC is the introduction of importance sampling to the ABC algorithm.
Hence, we first discuss the extension of \Cref{MFABC:Rejection} (MF-ABC-RS) to an importance sampling algorithm.
The extension will be analogous to the extension of \Cref{ABC:Rejection} (ABC-RS) into \Cref{ABC:Importance} (ABC-IS).
As in \Cref{ABC:Importance}, suppose that there exists a positive function $q(\theta)>0$ on $\Theta$ that induces an importance distribution $\hat q(\theta) = q(\theta)/Z_q$, satisfying the condition $\pi(\theta)>0 \Rightarrow q(\theta)>0$.
\Cref{MFABC:Importance} is an importance sampling algorithm that proposes parameters $\theta_n$ from $\hat q$, and weights $w_n = w(\tilde y_n, u_n, y_n, \theta_n)$ according to
\begin{equation}
\label{eq:qw_mf}
 w(\tilde y, u, y, \theta) 
 =
 \left[ \pi(\theta) \big/ q(\theta) \right] \cdot 
 \left( \mathbb I(\tilde y \in \Omega_\epsilon) + \frac{\mathbb I(u \leq \alpha)}{\alpha} \left( \mathbb I(y \in \Omega_\epsilon) - \mathbb I(\tilde y \in \Omega_\epsilon) \right) \right),
\end{equation}
which is a scaling of the multifidelity weight in \Cref{eq:w_mf}.
As in the proof of \Cref{MFABCValidity}, we can calculate $\mathbb E(w~|~\theta)$ by sequentially marginalising out the variables $u$, $\tilde y$, and $y$.
Thus, it is easily shown that the condition in \Cref{eq:ABCCondition} is satisfied, and that the Monte Carlo sample output by \Cref{MFABC:Importance} is therefore from the ABC posterior, $p_\epsilon(\theta~|~\obs y)$.

\begin{algorithm}
\caption{Multifidelity ABC importance sampling (MF-ABC-IS)}
\label{MFABC:Importance}
\begin{algorithmic}[1]
\REQUIRE{
Data $\obs y$ and neighbourhood $\Omega_\epsilon$; 
prior $\pi$; 
models $\tilde f(\cdot~|~\theta)$, $f(\cdot~|~\tilde y, \theta)$; 
continuation probability function $\alpha = \alpha(\tilde y, \theta)$; 
sample index $n=0$; 
importance distribution $\hat q$ proportional to $q(\theta)$; 
stopping condition $S$.}
\ENSURE{Weighted sample $\{ \theta_n, w_n \}_{n=1}^{N}$.}
\REPEAT{}
 \STATE{Increment $n \leftarrow n+1$.}
 \STATE{Generate $\theta_n \sim \hat q(\cdot)$.}
 \STATE{Simulate $\tilde y_n \sim \tilde f(\cdot~|~\theta_n)$.}
 \STATE{Set $w_n = \mathbb I \left( \tilde y_n \in \Omega_{\epsilon} \right)$.}
 \STATE{Generate $u_n \sim \mathrm{Uniform}(0,1)$.}
 \IF{$u_n < \alpha(\tilde y_n, \theta_n)$}
  \STATE{Simulate $y_n \sim f(\cdot ~|~ \tilde y_n, \theta_n)$.}
  \STATE{Update $w_n \leftarrow w_n + \left[ \mathbb I(y_n \in \Omega_\epsilon) - w_n \right] \big/ \alpha(\tilde y_n, \theta_n)$.}
 \ENDIF{}
 \STATE{Update $w_n \leftarrow \left[ \pi(\theta_n) \big/ q(\theta_n) \right] w_n$.}
\UNTIL{$S = \texttt{true}$.}
\end{algorithmic}
\end{algorithm}

We now have two functions to tune: the importance distribution, $\hat q$, by the choice of $q(\theta)$, and the continuation probability, $\alpha(\tilde y, \theta)$.
We defer the choice of continuation probability until \Cref{s:eta}, and next (following \Cref{s:SMC}) introduce the sequential importance sampling approach to specifying the importance distribution, $\hat q$.

\subsection{Multifidelity ABC sequential importance sampling}
\label{s:MF-ABC-SIS}

Suppose that, as in \Cref{s:SMC}, we have a decreasing sequence of thresholds, $\epsilon_1 > \dots > \epsilon_T = \epsilon$, inducing $T \geq 2$ neighbourhoods, $\Omega_{\epsilon_1} \supseteq \cdots \supseteq \Omega_{\epsilon_T}$, and ABC posteriors, $p_{\epsilon_t}(\theta~|~\obs y)$.
In principle, we can replace the call of \Cref{ABC:Importance} (ABC-IS) in step 2 of \Cref{ABC:SMC} with a call of \Cref{MFABC:Importance} (MF-ABC-IS) instead, and the sequential Monte Carlo approach would proceed in much the same way.
However, the key difficulty with implementing multifidelity ABC-SMC lies in the definition of the importance distribution, $\hat q_{t+1}$, for generation $t+1$, given the Monte Carlo sample, $\{ \theta_n^{(t)}, w_n^{(t)} \}_{n=1}^{N_t}$, returned in generation $t$. 

Since the weights, $w_n$, are now calculated using the multifidelity weight in \Cref{eq:qw_mf}, there is a positive probability that there exist $w_n < 0$.
Negative values of $w_n$ are generated whenever $\tilde y_n \in \Omega_\epsilon$, but where we also simulate the high-fidelity model and produce $y_n \notin \Omega_\epsilon$.
This leads to two problems with the existing definition of the importance distribution in \Cref{eq:importance}.
First, there is no longer a guarantee that $q_{t+1}(\theta) > 0$ whenever $\pi(\theta)>0$, even when the perturbation kernels, $K_t$, have infinite support.
Secondly, even if the $K_t$ could be chosen to guarantee $q_{t+1}(\theta)>0$, the method for sampling from the importance distribution, $\hat q_{t+1} \propto q_{t+1}$, is no longer valid: 
we cannot choose $\theta^{\star \star}$ from the set of $\{ \theta_n^{(t)} \}_{n=1}^{N_t}$ with probabilities proportional to $\{ w_n^{(t)} \}_{n=1}^{N_t}$, because any $w_n^{(t)} < 0$ cannot define a probability.

To overcome the first issue, we define a new importance distribution based on a parameter $0<\delta<1$ that uses the technique of defensive importance sampling~\cite{Owen2013} and enforces positivity.
Dropping the index $t$ for notational simplicity, we define the two functions
\begin{subequations}
\label{eq:DefensiveImportance}
\begin{align}
 r(\theta) &= \delta \pi(\theta) + (1-\delta) \max\left( 0, q(\theta) \right),
 \\
 q(\theta) &= \begin{cases}
                      \sum_{n=1}^{N} w_n K(\theta ~|~ \theta_n) \big/ \sum_{m=1}^{N} w_m & \pi(\theta)>0, 
                      \\
                      0 & \text{else,}
                    \end{cases}
\end{align}
\end{subequations}
where $q$ has exactly the same form given in \Cref{eq:importance}.
Clearly, $r(\theta) \geq \delta \pi(\theta)$ is positive for all $\theta$ such that $\pi(\theta)>0$, and it therefore induces a valid importance distribution $\hat r(\theta) = r(\theta)/Z_r$.
Furthermore, the parameter $\delta$ is useful because, by using $\hat r$ as the importance distribution in \Cref{eq:qw_mf}, we can enforce an upper bound of $\pi(\theta)/r(\theta) \leq 1/\delta$ on the ratio scaling the multifidelity weight.
The trade-off is that using $\delta>0$ will redistribute some of the importance density away from regions of high likelihood (where $q$ is large and positive) back onto the prior distribution.

The use of the positive function $r$ in place of $q$ transposes the question of how to sample from the importance distribution to apply to $\hat r$ in place of $\hat q$.
However, we can make use of the following procedure to sample from a distribution that is proportional to the difference of two other distributions~\cite{Rabusseau2014}.

\begin{lemma}
\label{negmix}
Let $f(x)$ and $g(x)$ be two probability density functions, and define the negative mixture
\[
 h(x) = \mu f(x) - (\mu - 1) g(x),
\]
for the constant $\mu > 1$. 
Define also the positive function $\phi$ such that $0 \leq \phi(x) \leq \mu f(x)$. 

Consider $x^\star$ generated according to the following rejection sampling procedure:
\begin{enumerate}
 \item Generate $x^\star \sim f(\cdot)$.
 \item Evaluate $\beta = \frac{(\mu-1)g(x^\star)}{\mu f(x^\star)}$ and $\gamma = \frac{\phi(x)}{\mu f(x)}$.
 \item With probability $\max(\gamma, 1-\beta)$ return $x^\star$ and end; else go to 1.
\end{enumerate}
Then $x^\star \sim \hat h^\phi(\cdot)$ where $\hat h^\phi(\cdot)$ is the normalised probability distribution proportional to $h^\phi(x) = \max(\phi(x), h(x))$.
\end{lemma}

To illustrate this sampling procedure, we let $f$ and $g$, respectively, be the probability density functions of $\mathrm{Beta}(1,2)$ and $\mathrm{Beta}(2,2)$ random variables.
Choosing $\mu = 3$, \Cref{fig:negative_mixture} shows that $h(x)<0$ on $x>0.5$.
We applied the sampling procedure in \Cref{negmix} for each of $\phi_0(x) \equiv 0$ and $\phi_1(x) = 0.3f(x)$ to produce $20,000$ sample values from $\hat h_{\phi_0}$ and $\hat h_{\phi_1}$, and plotted their histograms.
The acceptance probabilities in step (3) of \Cref{negmix} were $\max(0, 1-\beta)$ and $\max(0.1, 1 - \beta)$, respectively.
The results in \Cref{fig:negative_mixture} demonstrate that we can sample from a negative mixture and simultaneously specify a positive lower bound on the resulting density.

\begin{figure}
\centering
\begin{subfigure}[b]{0.48\textwidth}
 \includegraphics[width=\textwidth]{negative_mixture_A}
 \caption{Sampling from $\hat h_{\phi_0} \propto h_{\phi_0} = \max(0,h)$.}
 \label{fig:negative_mixture_A}
\end{subfigure}
~
\begin{subfigure}[b]{0.48\textwidth}
 \includegraphics[width=\textwidth]{negative_mixture_B}
 \caption{Sampling from $\hat h_{\phi_1} \propto h_{\phi_1} = \max(0.3f, h)$.}
 \label{fig:negative_mixture_B}
\end{subfigure}
\caption{Sampling from a negative mixture. Here, $f$ and $g$ are the probability density functions of $\mathrm{Beta}(1,2)$ and $\mathrm{Beta}(2,2)$ distributions.}
\label{fig:negative_mixture}
\end{figure}

Using the procedure outlined in \Cref{negmix}, we can show that \Cref{NegativeResample} produces samples from the importance distribution $\hat r$ proportional to the function $r$ in \Cref{eq:DefensiveImportance}.
In the outlined procedure of \Cref{negmix}, step 1 is performed by lines 3 to 12, which produce a proposal $\theta^{\star \star}$.
The quantities in step 2 are computed in lines 13 and 14, and step 3 is applied by the if statement at the end.
Note that the weights are normalised in step 1, to ensure that the defensive importance sampling parameter, $\delta$, reliably specifies the fraction of $r$ that is contributed by the prior, $\pi$.

\begin{algorithm}
\caption{Sample from $\hat r(\cdot)$ proportional to $r(\cdot)$ in \Cref{eq:DefensiveImportance}.}
\label{NegativeResample}
\begin{algorithmic}[1]
\REQUIRE{
Weighted sample $\{ \theta_n, w_n \}_{n=1}^{N}$ with $\sum_{n=1}^N w_n > 0$; 
perturbation kernels $K(\cdot~|~\theta_n)$; 
prior $\pi(\cdot)$; 
defensive parameter $\delta \in (0,1)$.
}
\ENSURE{Single sample point $\theta^{\star \star}$ from importance distribution $\hat r(\cdot)$.}
\STATE{Normalise the weights $w_n \leftarrow w_n \big/ \sum_{m=1}^N w_m$.}
\STATE{For the index subset $A = \{ n~:~w_n>0 \}$, calculate $\zeta_+ = \sum_{n \in A} w_n$.}
\STATE{Generate independent $u_1, u_2 \sim \mathrm{Unif}(0,1)$.}
\IF{$u_1 < \delta \big/ (\delta + (1-\delta) \zeta_+)$}
 \STATE{Select $\theta^{\star \star} \sim \pi(\cdot)$.}
\ELSE{}
 \STATE{Choose $\theta^\star$ from the set $\left\{ \theta_n \right\}_{n \in A}$ with probability distribution $\left\{ w_n \big/ \zeta_+ \right\}_{n \in A}$.}
\STATE{Generate $\theta^{\star \star} \sim K \left( \cdot~|~\theta^\star \right)$.}
\IF{$\pi(\theta^{\star \star}) = 0$}
 \STATE{Return to 3.}
\ENDIF{}
\ENDIF{}
\STATE{Calculate 
\begin{align*}
F &= \delta \pi(\theta^{\star \star}) + (1-\delta) \sum_{n \in A} w_n K(\theta^{\star \star} ~|~ \theta_n), \\
G &= (1-\delta) \sum_{n \notin A} \left| w_n \right| K(\theta^{\star \star} ~|~ \theta_n).
\end{align*}
}
\STATE{Calculate $\beta = G/F$ and $\gamma = \delta \pi(\theta^{\star \star}) / F$ .}
\IF{$u_2 < \max( \gamma, 1-\beta) $}
 \STATE{Return $\theta^{\star\star}$.}
\ELSE{}
\STATE{Return to 3.}
\ENDIF{}
\end{algorithmic}
\end{algorithm}

\begin{proposition}
The sample point $\theta$ returned by \Cref{NegativeResample} is a random draw from the probability density function proportional to $r$ in \Cref{eq:DefensiveImportance}.
\end{proposition}
\begin{proof}
Without loss of generality, assume that $\sum w_n = 1$.
We can bring the $\delta \pi(\theta)$ term inside the maximum and write $r = \max(\delta \pi, \delta \pi + (1-\delta) q)$.
For the index subset $A = \{ n~:~w_n>0 \}$, we can split the sum in $q$ into two sums, across $n \in A$ and $n \notin A$, respectively.
Then $\delta \pi + (1-\delta) q$ is of the form $h = \mu f - (\mu - 1) g$ in \Cref{negmix}, where
\begin{align*}
f(\theta) &= \frac{\delta}{\mu} \pi(\theta) + \sum_{n \in A} \frac{(1-\delta) w_n}{\mu} K(\theta~|~\theta_n),
\\
g(\theta) &= \sum_{n \notin A} \frac{(1-\delta)\left|w_n\right|}{\mu - 1} K(\theta~|~\theta_n),
\\
\mu &= \delta + (1-\delta) \sum_{n \in A} w_n.
\end{align*}
Since $\sum_{n \in A} w_n \geq \sum_n w_n = 1$, we have $\mu \geq 1$ and hence $\delta \pi + (1-\delta) q$ is a negative mixture.
Furthermore, since $\phi(\theta) = \delta \pi(\theta)$ satisfies $0 \leq \phi\leq \mu f$, the procedure in \Cref{negmix} can be applied to $r$.
\end{proof}

In \Cref{fig:negative_mixture_q} we show a histogram of $50,000$ sample points generated by \Cref{NegativeResample}, and compare that to the theoretical value of $\hat r$.
The parameters and weights of the Monte Carlo sample are such that $q(\theta) < 0$ in a region of parameter space. 
However, \Cref{NegativeResample} returns a small, positive proportion of $\theta$ in this region, albeit with the smallest likelihood allowed by the lower bound of $\delta \pi$ on $r$.
Note that if it is possible to show that $q>0$ on the support of $\pi$, then we can set $\delta=0$.
One obvious such scenario is when there are no negative weights in the Monte Carlo sample.

\begin{figure}
\centering
\includegraphics[width=0.95\columnwidth]{negative_mixture_q}
\caption{
Sampling from \Cref{NegativeResample} for $\hat r$ given by \Cref{eq:DefensiveImportance}, formed from four parameter values $\theta_n \in \{-0.5, 0, 0.5, 1\}$ with corresponding weights $w_n \in \{2, 1, 1, -0.75\}$. 
The perturbation kernels $K(\cdot~|~\theta_n)$ are Gaussian, centred at $\theta_n$ with standard deviation $0.4$.
The weighted perturbation kernels are displayed using dotted blue lines. 
The prior is $\pi \sim \mathrm{Unif}(-2, 2)$, and the defensive importance sampling parameter is $\delta = 0.1$.
}
\label{fig:negative_mixture_q}
\end{figure}

\subsection{Optimal continuation probabilities}
\label{s:eta}

We are now almost in a position to fully outline a multifidelity ABC-SMC algorithm.
We have defined an MF-ABC importance sampling algorithm in \Cref{MFABC:Importance}, and we have shown how to construct and sample from an importance distribution formed from a multifidelity Monte Carlo sample in \Cref{eq:DefensiveImportance} and \Cref{NegativeResample}.
However, in order to use \Cref{MFABC:Importance} (MF-ABC-IS) in place of \Cref{ABC:Importance} (ABC-IS) in an SMC algorithm, we also need to supply a continuation probability, $\alpha(\tilde y, \theta)$, in addition to the importance distribution.
Up to now, we have assumed that $\alpha$ is known, but we will now consider how to choose $\alpha$ to maximise the theoretical efficiency, $\psi$, of \Cref{MFABC:Importance} (MF-ABC-IS), as specified in \Cref{def:efficiency:th}.

For simplicity, we will constrain the search for optimal $\alpha(\tilde y, \theta)$ to the piecewise constant function
\begin{equation}
\label{eq:constantrates}
 \alpha(\tilde y, \theta) = \eta_1 \mathbb I(\tilde y \in \Omega_{\epsilon}) + \eta_2 \mathbb I(\tilde y \notin \Omega_{\epsilon}),
\end{equation}
for the constants $\eta_1, \eta_2 \in (0,1]$.
Here, $\eta_1$ is the probability of generating $y$ after a `positive' low-fidelity simulation (where $\tilde y \in \Omega_\epsilon$) and $\eta_2$ is the probability of generating $y$ after a `negative' low-fidelity simulation (where $\tilde y \notin \Omega_\epsilon$).
The goal of this section is to specify the values of the two parameters, $\eta_1$ and $\eta_2$, that will give the largest theoretical efficiency, $\psi$.
In previous work, we have derived the optimal values of $\eta_1$ and $\eta_2$ to use in \Cref{MFABC:Rejection} (MF-ABC-RS)~\cite{Prescott2020}.
We can now extend this analysis by finding optimal values of $\eta_1$ and $\eta_2$ to use in \Cref{MFABC:Importance} (MF-ABC-IS).

The strategy for choosing continuation probabilities will be presented as follows.
In \Cref{s:eta:exact}, we show how to maximise the theoretical efficiency of \Cref{MFABC:Importance} (MF-ABC-IS).
We derive expressions for the continuation probabilities, $\eta_1^\star$ and $\eta_2^\star$, that optimise the efficiency, $\psi(\eta_1,\eta_2)$, when formulated as a function of the continuation probabilities.
These expressions can be written in terms of expected simulation times and the probabilities of the events $\tilde y, y \in \Omega_\epsilon$.
In \Cref{s:eta:MC}, we provide a practical method for calculating near-optimal continuation probabilities, derived from the optima found in \Cref{s:eta:exact}.

\subsubsection{Optimising theoretical efficiency}
\label{s:eta:exact}

The following lemma describes how the efficiency of \Cref{MFABC:Importance} varies with the continuation probabilities used, for a given importance distribution, $\hat q(\theta)$. 

\begin{lemma}
\label{lemma:phi}
The theoretical efficiency, given in \Cref{def:efficiency:th}, of \Cref{MFABC:Importance} (MF-ABC-IS) varies with the continuation probabilities $\eta_1$ and $\eta_2$ according to
\[
\psi(\eta_1,\eta_2) = \frac{\mathbb E(w)^2}{\mathbb E(w^2) \mathbb E(T)} = \frac{Z^2}{\phi(\eta_1, \eta_2)},
\]
where $Z = p(y \in \Omega_\epsilon)$ is the normalisation constant of the ABC posterior in \Cref{eq:ABCposterior}, and where
\begin{equation}
\label{eq:Phi}
\phi(\eta_1, \eta_2) = 
\left(  W + \left( \frac{1}{\eta_1} - 1 \right) \fp W + \left( \frac{1}{\eta_2} - 1 \right) \fn W \right)
\left( \bar{T}_{\mathrm{lo}}
 + \eta_1 \bar T_{\mathrm{hi}, \mathrm p}
 + \eta_2 \bar T_{\mathrm{hi}, \mathrm n} \right).
\end{equation}
The coefficients in $\psi$ are given by the integrals
\begin{subequations}
\label{eq:PhiComponents}
\begin{align}
\label{eq:Z}
Z &= \int \pi(\theta) f_\epsilon(\obs y~|~\theta) ~\mathrm d\theta
,&
&f_\epsilon(\obs y~|~\theta) = \mathbb E \left(\mathbb I(y \in \Omega_\epsilon) ~|~\theta \right) 
,\\
W &= \int \frac{\pi(\theta)^2 f_\epsilon(\obs y~|~\theta)}{q(\theta)} ~\mathrm d\theta
,\\
\fp W &= \int \frac{\pi(\theta)^2 \fp p(\theta)}{q(\theta)} ~\mathrm d\theta 
,&
&\fp p(\theta) = \mathbb E \left(\mathbb I ( \tilde y \in \Omega_\epsilon) \mathbb I(y \notin \Omega_\epsilon) ~|~\theta \right) 
,\\
\fn W &= \int \frac{\pi(\theta)^2 \fn p(\theta)}{q(\theta)} ~\mathrm d\theta 
,&
&\fn p(\theta) = \mathbb E \left(\mathbb I ( \tilde y \notin \Omega_\epsilon) \mathbb I(y \in \Omega_\epsilon) ~|~\theta \right) 
,\\
\bar T_{\mathrm{lo}} &= \int T_{\mathrm{lo}}(\theta) q(\theta) ~\mathrm d\theta
,&
&T_{\mathrm{lo}}(\theta) = \mathbb E(T(\tilde y) ~|~\theta)
,\\
\bar T_{\mathrm{hi,p}} &= \int T_{\mathrm{hi,p}}(\theta) q(\theta) ~\mathrm d\theta
,&
&T_{\mathrm{hi,p}}(\theta) = \mathbb E\left( T(y) \mathbb I(\tilde y \in \Omega_\epsilon) ~|~ \theta \right)
,\\
\bar T_{\mathrm{hi,n}} &= \int T_{\mathrm{hi,n}}(\theta) q(\theta) ~\mathrm d\theta
,&
&T_{\mathrm{hi,n}}(\theta) = \mathbb E\left( T(y) \mathbb I(\tilde y \notin \Omega_\epsilon) ~|~ \theta \right)
,
\end{align}
\end{subequations}
where $T(y)$ is the amount of time taken to generate $y$ (similarly for $\tilde y$), and where the expectations are taken over the joint density $f(y~|~\tilde y, \theta) \tilde f(\tilde y~|~\theta)$.
\end{lemma}

As before, $Z$ is the normalisation constant in the ABC posterior definition in \Cref{eq:ABC}.
The coefficient $W$ can be written $W = Z \mathbb E_{p_\epsilon}(\pi/q)$, as the posterior expectation of the ratio $\pi / q$, scaled by $Z$.
The average time taken to simulate $\tilde y$ from the low-fidelity model is given by $\bar T_{\mathrm{lo}}$.
The final two coefficients, $\bar T_{\mathrm{hi,p}}$ and $\bar T_{\mathrm{hi,n}}$, represent the average time taken to simulate $y$ from the high-fidelity model, conditional on whether or not the low-fidelity simulation satisfies $\tilde y \in \Omega_\epsilon$.
These coefficients therefore determine how much time can be saved if we set $\eta_1,\eta_2 < 1$, thereby avoiding some simulations from $f$.

The key determinants of the success of the multifidelity technique are $\fp W$ and $\fn W$.
Smaller values of $\fp W$ and $\fn W$ correspond to a smaller cost to the efficiency of allowing $\eta_1,\eta_2<1$.
These coefficients can be written as
\begin{align*}
 \fp W 
 &= 
 \mathbb E \left( \frac{\pi^2}{q^2} ~\bigg|~ \tilde y \in \Omega_\epsilon ~\cap~ y \notin \Omega_\epsilon \right) \mathbb P \left( \tilde y \in \Omega_\epsilon ~\cap~ y \notin \Omega_\epsilon \right),
 \\
 \fn W 
 &= 
 \mathbb E \left( \frac{\pi^2}{q^2} ~\bigg|~ \tilde y \notin \Omega_\epsilon ~\cap~ y \in \Omega_\epsilon \right) \mathbb P \left( \tilde y \notin \Omega_\epsilon ~\cap~ y \in \Omega_\epsilon \right),
\end{align*}
where the expectations and probabilities are in terms of the density $f(y~|~\tilde y, \theta) \tilde f(\tilde y~|~\theta) \hat q(\theta)$.
Thus, they are scalings of the probabilities of a false positive (where $\tilde y \in \Omega_\epsilon$ but $y \notin \Omega_\epsilon$) and a false negative (where $\tilde y \notin \Omega_\epsilon$ but $y \in \Omega_\epsilon$), respectively.
Each is scaled by the conditional expectation of $\pi^2 / q^2$, conditioned on the false positive and false negative events, respectively.
Hence, small values of $\fp W$ and $\fn W$ correspond to at least one of the following cases.
First, if the low-fidelity and high-fidelity models are closely correlated, then the probability of a false positive or false negative is small.
This demonstrates the value of coupling the models, as described in \Cref{s:MFABC}.
Second, for small values of $\fp W$ and $\fn W$ we require $q$ to be larger than $\pi$ in regions of parameter space where false positives or false negatives are relatively likely.
We can intepret this as a requirement that the region of parameter space where simulations of the low-fidelity and high-fidelity model are less often in agreement (in terms of membership of $\Omega_\epsilon$) should be explored more thoroughly by $\hat q$ than by $\pi$.

The consequence of \Cref{lemma:phi} is that we should choose continuation probabilities $\eta_1,\eta_2>0$ to maximise the theoretical efficiency, $\psi$, by minimising $\phi$ in \Cref{eq:Phi}.
It is clear from \Cref{eq:Phi} that the cost to the algorithm's efficiency of using $\eta_1$ or $\eta_2$ too small (i.e. too close to zero) is much greater than using larger values (i.e. closer to $1$).
Therefore, we conservatively optimise $\phi$ in the region $(\eta_1,\eta_2) \in \mathcal H = [\rho_1,1] \times [\rho_2, 1]$, defined by user-specified lower bounds $\rho_1, \rho_2 > 0$ on the continuation probabilities.
We proceed by first optimising $\phi$ on the entire positive quadrant in \Cref{etastar:unbounded}, and also on the boundary $\partial \mathcal H$ of $\mathcal H$ in \Cref{etastar:boundary}. 
These lemmas combine in \Cref{etastar}, where we derive the continuation probabilities $(\eta_1^\star, \eta_2^\star) \in \mathcal H$ that minimise $\phi$ and hence maximise $\psi$.

\begin{lemma}
\label{etastar:unbounded}
 We first consider all non-negative values of $\eta_1, \eta_2 \geq 0$. 
 If $W > \fp{W} + \fn{W}$, then the minimum value of $\phi(\eta_1,\eta_2)$ in \Cref{eq:Phi}, and the optimal value of $(\eta_1, \eta_2)$ in the entire positive quadrant, are given by
 \begin{subequations}
 \label{eq:etastar:unbounded}
 \begin{align}
  \bar \phi &= \left( \sqrt{(W - \fp{W} - \fn{W}) \bar T_{\mathrm{lo}}} + \sqrt{\fp{W} \bar T_{\mathrm{hi, p}}} + \sqrt{\fn{W} \bar T_{\mathrm{hi, n}}} \right)^2, \\
  \left( \bar \eta_1, \bar \eta_2 \right) &= \left( 
  	\sqrt{ \frac{\bar T_{\mathrm{lo}}}{W - \fp{W} - \fn{W}} \cdot \frac{\fp{W}}{\bar T_{\mathrm{hi, p}} }},
	\sqrt{ \frac{\bar T_{\mathrm{lo}}}{W - \fp{W} - \fn{W}} \cdot \frac{\fn{W}}{\bar T_{\mathrm{hi, n}} }}
  \right),
 \end{align}
 \end{subequations}
 respectively.
 If $W \leq \fp{W} + \fn{W}$, then there is no minimum of $\phi(\eta_1,\eta_2)$ in $\eta_1, \eta_2 > 0$.
\end{lemma}

\begin{lemma}
\label{etastar:boundary} 
 Under the same conditions as \Cref{etastar:unbounded}, fix the region $\mathcal H = [\rho_1, 1] \times [\rho_2, 1]$ of valid continuation probabilities with positive user-defined lower bounds $\rho_1, \rho_2 > 0$.
Define the two functions, for $x>0$,
\begin{subequations}
\label{eq:etastar:boundary}
\begin{align}
\eta_1(x) &= \max \left\{ \rho_1, ~\min \left[ 1, 
\sqrt{\frac{\bar T_{\mathrm{lo}} + \bar T_{\mathrm{hi}, \mathrm{n}} x }{W - \fp{W} - (1-x^{-1})\fn{W}} \cdot \frac{\fp{W}}{\bar T_{\mathrm{hi}, \mathrm p}}} ~
\right] \right\}, \\
\eta_2(x) &= \max \left\{ \rho_2, ~\min \left[ 1, 
\sqrt{\frac{\bar T_{\mathrm{lo}} + \bar T_{\mathrm{hi}, \mathrm{p}} x }{W - (1-x^{-1}) \fp{W} - \fn{W}} \cdot \frac{\fn{W}}{\bar T_{\mathrm{hi}, \mathrm n}}} ~
 \right] \right\}.
\end{align}
\end{subequations}
Then the minimum value of $\phi$ on the boundary, $\partial \mathcal H$, of $\mathcal H$ is attained at the minimum of $\phi(1, \eta_2(1))$, $\phi(\eta_1(1), 1)$, $\phi(\rho_1, \eta_2(\rho_1))$ or $\phi(\eta_1(\rho_2), \rho_2)$.
\end{lemma}
 
\begin{proposition}
\label{etastar}
 Assume the same conditions as \Cref{etastar:unbounded,etastar:boundary}. 
 Compute the minimiser, $(\bar \eta_1, \bar \eta_2)$, and minimal value, $\bar \phi$, of $\phi$ in $(0,\infty)^2$ using \Cref{etastar:unbounded}, if they exist.
 If $(\bar \eta_1, \bar \eta_2) \in \mathcal H$ then set $(\eta_1^\star, \eta_2^\star) = (\bar \eta_1, \bar \eta_2)$ and $\phi^\star = \bar \phi$. 
 Otherwise, set $\phi^\star$ equal to the minimum of the four values of $\phi$ listed in \Cref{etastar:boundary}, and $(\eta_1^\star, \eta_2^\star)$ to the associated argument.
Then $\phi^\star$ is the minimum value of $\phi$ over $(\eta_1, \eta_2) \in \mathcal H$, and $(\eta_1^\star, \eta_2^\star)$ are the minimising continuation probabilities.
\end{proposition}

There is an important barrier to implementing \Cref{etastar} as a method for choosing optimal continuation probabilities.
Before running any ABC iterations, and in the absence of extensive analysis of the models being simulated, the quantities in \Cref{eq:PhiComponents} are unknown.
Therefore $\phi$ and $\psi$ cannot be determined \emph{a priori}, and the optimal continuation probabilities cannot be calculated.
In \Cref{s:eta:MC} we consider how to exploit the SMC approach to construct near-optimal continuation probabilities. 

\subsubsection{Constructing continuation probabilities}
\label{s:eta:MC}

Recall that we are aiming to use this method in the context of sequential Monte Carlo.
In the sequential importance sampling approach discussed in \Cref{s:SMC,s:MF-ABC-SIS}, we use a Monte Carlo sample from generation $t$ to construct the importance distribution, $\hat q_{t+1}$ or $\hat r_{t+1}$, for use in generation $t+1$.
The proposed approach to constructing continuation probabilities is the same: we will use the Monte Carlo sample built in generation $t$ to also produce the values of $\eta_1$ and $\eta_2$ defining the continuation probability $\alpha_{t+1}$ to use at generation $t+1$.
The following definition specifies how to calculate approximations of the quantities in \Cref{eq:PhiComponents} using an existing Monte Carlo sample.
These approximations can then be substituted into \Cref{eq:etastar:unbounded,eq:etastar:boundary}.
Hence, we can estimate the optimal continuation probabilities as given by \Cref{etastar}.

\begin{definition}
\label{def:MonteCarlo}
Consider a Monte Carlo sample $\left\{ \theta_n, w_n \right\}_{n=1}^{N}$ constructed from a run of \Cref{MFABC:Importance} with importance distribution $\hat r(\theta)$ proportional to $r(\theta)$ and continuation probability $\alpha(\tilde y, \theta)$.
For the set of low-fidelity simulations $\{ \tilde y_n \}_{n=1}^{N}$ and high-fidelity simulations $\{ y_n \}_{n \in M}$, where $M = \{ n~:~ y_n \text{ exists} \}$, store: the simulation times, $\tilde t_n = T(\tilde y_n)$ and $t_n = T(y_n)$; the distances, $\tilde d_n = d(\tilde y_n, \obs y)$ and $d_n = d(y_n, \obs y)$; the (unnormalised) importance densities $r_n = r(\theta_n)$; and the continuation probabilities $\alpha_n = \alpha(\tilde y_n, \theta_n)$.

We now consider a new run of \Cref{MFABC:Importance} with importance distribution, $\hat q$, proportional to $q$, and the threshold, $\epsilon$.
We define the Monte Carlo estimates,
\begin{subequations}
\label{eq:MonteCarlo}
\begin{align}
 \hat Z &= \frac{1}{N} \left[ \sum_{n=1}^N \frac{\pi(\theta_n)}{r_n} \mathbb I(\tilde d_n < \epsilon) + \sum_{n \in M} \frac{\pi(\theta_n)}{r_n \alpha_n} \left( \mathbb I(d_n < \epsilon) - \mathbb I(\tilde d_n < \epsilon)\right) \right]
 \label{eq:Zhat}
, \\
 \hat{W} &= \frac{1}{N} \left[ \sum_{n=1}^N \frac{\pi(\theta_n)^2}{q(\theta_n) r_n} \mathbb I(\tilde d_n < \epsilon) + \sum_{n \in M} \frac{\pi(\theta_n)^2}{q(\theta_n) r_n \alpha_n} \left( \mathbb I(d_n < \epsilon) - \mathbb I(\tilde d_n < \epsilon)\right) \right]
 \label{eq:MC_tpfn}
, \\ \fp{\hat{W}} &= \frac{1}{N} \sum_{n \in M} \frac{ \pi(\theta_n)^2  \mathbb I (\tilde d_n < \epsilon) \mathbb I (d_n \geq \epsilon)}{q(\theta_n) r_n \alpha_n}
 \label{eq:MC_fp}
, \\ \fn{\hat{W}} &= \frac{1}{N} \sum_{n \in M} \frac{ \pi(\theta_n)^2 \mathbb I (\tilde d_n \geq \epsilon) \mathbb I (d_n < \epsilon)}{q(\theta_n) r_n \alpha _n} 
 \label{eq:MC_fn}
, \\ \hat T_{\mathrm{lo}} &= \frac{1}{N} \sum_{n=1}^{N} \frac{q(\theta_n)}{r_n} \tilde t_n
 \label{eq:T_lo}
, \\ \hat T_{\mathrm{hi}, \mathrm p} &= \frac{1}{N} \sum_{n \in M} \frac{q(\theta_n)}{r_n \alpha_n} \mathbb I(\tilde d_n < \epsilon) t_n
 \label{eq:T_hi_p}
, \\ \hat T_{\mathrm{hi}, \mathrm n} &= \frac{1}{N} \sum_{n \in M} \frac{q(\theta_n)}{r_n \alpha_n} \mathbb I(\tilde d_n \geq \epsilon) t_n
 \label{eq:T_hi_n}
,
\end{align}
\end{subequations}
corresponding to the quantities in \Cref{eq:PhiComponents}.
\end{definition}

The estimates in \Cref{eq:MonteCarlo} are scaled Monte Carlo estimates of the quantities in \Cref{eq:PhiComponents}, such that the approximation
\[
\psi(\eta_1,\eta_2) = \frac{Z^2}{\phi(\eta_1,\eta_2)} \approx \frac{\hat Z^2}{\hat \phi(\eta_1,\eta_2)},
\]
holds, with
\begin{equation}
\label{eq:PhiHat}
\hat \phi(\eta_1, \eta_2) = 
\left(  \hat W + \left( \frac{1}{\eta_1} - 1 \right) \fp{\hat W} + \left( \frac{1}{\eta_2} - 1 \right) \fn{\hat W} \right)
\left( \hat{T}_{\mathrm{lo}}
 + \eta_1 \hat T_{\mathrm{hi}, \mathrm p}
 + \eta_2 \hat T_{\mathrm{hi}, \mathrm n} \right).
\end{equation}
Thus, we can substitute the estimates in \Cref{eq:MonteCarlo} into \Cref{eq:etastar:unbounded,eq:etastar:boundary}.
Applying \Cref{etastar} with these estimates thus provides near-optimal continuation probabilities for the new run of \Cref{MFABC:Importance}, constructed from the existing Monte Carlo sample.

\begin{note}
The values $r_n = r(\theta_n)$ are not normalised, and therefore the quantities in \Cref{eq:MonteCarlo} are Monte Carlo estimates of the quantities in \Cref{eq:PhiComponents}, but scaled by the unknown normalising constant $Z_r = \hat r(\theta)/r(\theta)$.
However, the normalising constants cancel out in the ratio $\hat Z^2/\hat \phi$, and so without loss of generality we can assume that $\hat r = r$.
\end{note}

\begin{note}
The Monte Carlo estimates in \Cref{eq:MonteCarlo} are not independent of each other, so there is a bias in the approximation $\hat Z^2 / \hat \phi$.
Hence, the continuation probabilities $(\eta_1^\star, \eta_2^\star)$ returned by \Cref{etastar}, if using the estimates in \Cref{eq:MonteCarlo}, can only be near-optimal. 
\end{note}


\subsection{MF-ABC-SMC algorithm}
\label{s:MFABC:SMC}

In \Cref{s:MF-ABC-IS,s:MF-ABC-SIS,s:eta}, we have tackled three challenges related to the development of an SMC implementation of multifidelity ABC.
First, \Cref{s:MF-ABC-IS} introduces an importance sampling algorithm that uses the multifidelity framework to speed calculation of the weights by avoiding some simulations of the high-fidelity model.
The resulting \Cref{MFABC:Importance} (MF-ABC-IS) requires an importance distribution and continuation probability to be specified.
Then, in \Cref{s:MF-ABC-SIS} we described how to use an output of \Cref{MFABC:Importance} to construct an importance distribution, analogously to the approach taken in \Cref{ABC:SMC} (ABC-SMC).
We overcame the issue of negative weights in order to ensure that the resulting importance distribution, defined in \Cref{eq:DefensiveImportance}
(a) was positive in the prior support,
and (b) could be sampled from, as described in \Cref{NegativeResample}.
Finally, in \Cref{s:eta} we described how to use the same Monte Carlo sample output by \Cref{MFABC:Importance} to generate a continuation probability, limiting our discussion to a piecewise constant continuation probability function of the form in \Cref{eq:constantrates}.
\Cref{etastar} defines a method for calculating continuation probabilities that optimises the theoretical efficiency of generating a new sample from \Cref{MFABC:Importance}.

Taking these three contributions together, \Cref{MFABC:SMC} (MF-ABC-SMC) is a multifidelity sequential Monte Carlo algorithm for ABC parameter inference.
In addition to the inputs to \Cref{ABC:SMC} (ABC-SMC), we additionally require the low-fidelity model, $\tilde f(\cdot~|~\theta)$ and (optionally) the coupled high-fidelity model $f(\cdot~|~\tilde y,\theta)$.
We also require lower bounds, $\rho_1$ and $\rho_2$, on the allowed values of the continuation probabilities, and a small positive parameter, $\delta$, to ensure positivity of the importance distribution in \Cref{eq:DefensiveImportance}.
Since the final sample is generated by a run of \Cref{MFABC:Importance}, by the argument in \Cref{s:MF-ABC-IS} it follows that the sample is from the ABC posterior, $p_\epsilon(\theta~|~\obs y)$.

\begin{algorithm}
\caption{Multifidelity ABC-SMC (MF-ABC-SMC)}
\label{MFABC:SMC}
\begin{algorithmic}[1]
\REQUIRE{
Data $\obs y$ and sequence of nested neighbourhoods $\Omega_{\epsilon_T} \subseteq \Omega_{\epsilon_{T-1}} \subseteq \cdots \subseteq \Omega_{\epsilon_1}$ for $0 < \epsilon = \epsilon_T < \epsilon_{T-1} < \dots < \epsilon_1$; 
prior $\pi$; 
perturbation kernels $K_t(\cdot~|~\theta)$; 
initial importance distribution $\hat r_1$ (often set to $\pi$); 
models $\tilde f(\cdot~|~\theta)$, $f(\cdot~|~\tilde y, \theta)$; 
lower bounds on continuation probabilities, $\rho_1$, $\rho_2$; 
defensive importance sampling parameter $0<\delta\ll 1$; 
stopping conditions $S_1, S_2, \dots, S_T$.
}
\ENSURE{
Weighted sample $\{\theta_n^{(T)}, w_n^{(T)} \}_{n=1}^{N_T}$.
}
\STATE{Set $\eta_1^\star = \eta_2^\star = 1$ and $\alpha_1(\tilde y, \theta) \equiv 1$.}
\FOR{$t = 1, \dots, T-1$}
 \STATE{\% \emph{Produce a sample for generation $t$}:}
 \STATE{Produce $\{ \theta_n^{(t)}, w_n^{(t)}  \}_{n=1}^{N_t}$ from \Cref{MFABC:Importance} (MF-ABC-IS), using the neighbourhood $\Omega_{\epsilon_t}$, continuation probability $\alpha_t$, importance distribution $\hat r_t$, and stopping condition $S_t$.
 Store simulation times, distances, importance densities and continuation probabilities as specified in \Cref{def:MonteCarlo}.}
 \STATE{\% \emph{Define the next generation's importance distribution:}}
 \STATE{Define $\hat r_{t+1}$ proportional to $r_{t+1}$ given in \Cref{eq:DefensiveImportance}, with sampling algorithm given by \Cref{NegativeResample}. 
 Use $\delta = 0$ if $w_n^{(t)} > 0$ for all $n$, else use specified $\delta$.}
 \STATE{\% \emph{Choose the next generation's continuation probabilities:}}
 \STATE{Update the estimates in \Cref{eq:MonteCarlo} with the values stored at step 4, using the importance distribution proportional to $r_{t+1}(\theta)$ and threshold $\epsilon_{t+1}$.}
 \STATE{Update $(\eta_1^\star, \eta_2^\star)$ using \Cref{etastar} with lower bounds $\rho_1, \rho_2 > 0$.}
 \STATE{Set $\alpha_{t+1}(\tilde y, \theta) = \eta_1^\star \mathbb I(\tilde y \in \Omega_{\epsilon}) + \eta_2^\star \mathbb I(\tilde y \notin \Omega_{\epsilon})$. }
\ENDFOR{}
\STATE{Produce $\{ \theta_n^{(T)}, w_n^{(T)} \}_{n=1}^{N_T}$ from \Cref{MFABC:Importance}, using neighbourhood $\Omega_{\epsilon}$, continuation probability $\alpha_T$, importance distribution $\hat r_T$ and stopping condition $S_T$.}

\end{algorithmic}
\end{algorithm}


\section{Example: Kuramoto Oscillator Network}
\label{s:Example}

To demonstrate the multifidelity and SMC approaches to parameter inference, we will apply \Cref{ABC:Rejection,ABC:SMC,MFABC:Rejection,MFABC:SMC} to infer the parameters of a Kuramoto oscillator model on a complete network with stochastic heterogeneity in each node's intrinsic frequency.
In \Cref{s:existing} we consider the performance of the previously developed ABC algorithms introduced in \Cref{s:Background} (ABC-RS, ABC-SMC, and MF-ABC-RS).
In \Cref{s:Results} we apply \Cref{MFABC:SMC} (MF-ABC-SMC), as introduced in \Cref{s:MF-ABC-SMC}, and demonstrate that the efficiency of parameter estimation is significantly improved by combining the multifidelity and SMC approaches.
The algorithms have been implemented in Julia~\cite{Julia} and the source code can be found at \url{github.com/tpprescott/mf-abc-smc}.

The model is defined on a complete network of $M$ nodes, where each node, $i$, has a phase value, $\phi_i$, with dynamics determined by the ordinary differential equation
\begin{equation}
 \label{eq:Kuramoto_hi}
 \dot \phi_i  = \omega_i + \frac{K}{M} \sum_{j=1}^{M} \sin \left( \phi_j - \phi_i \right),
\end{equation}
for $i=1,\dots,M$.
Each $\omega_i$, the intrinsic angular velocity, is an independent draw from a Cauchy distribution with median $\omega_0$ and dispersion parameter $\gamma$. 
In addition to these two parameters, we have an interconnection strength $K$.
Simulations of the ODE system are run over a fixed time interval $t \in [0,T]$, and we will assume fixed initial conditions $\phi_i(0)=0$ for all $i$.

The multifidelity approach makes use of a low-dimensional approximation of the coupled oscillator dynamics, as described in~\cite{Hannay2018,Ott2008,Ott2009}.
The approximation is based on tracking the Daido order parameters, which are a set of complex-valued representations of the high-dimensional vector $(\phi_i)_{i=1}^M$, defined as
\[
 Z_n(t) = \frac{1}{M} \sum_{j=1}^M \exp( i n \phi_j),
\]
for positive integers $n$ and the imaginary unit $i$.
A system of coupled ODEs can be generated for the set of $Z_n$.
Under the assumption that $Z_n(t) = Z_1(t)^n$, known as the Ott-Antonsen ansatz~\cite{Hannay2018,Ott2008}, the system can be reduced to a single ODE for $Z_1$, which is known as the Kuramoto parameter.
This complex-valued trajectory is usually represented by two real trajectories, corresponding to its magnitude $R(t) = \| Z_1(t)) \|$ and phase $\Phi(t) = \arg(Z_1(t))$.
The approximation of the $M$-dimensional ODE system in \Cref{eq:Kuramoto_hi} under the OA ansatz is thus given by the two-dimensional ODE system
\begin{subequations}
\label{eq:Kuramoto_lo}
\begin{align}
 \dot{\tilde R} &= \left( \frac{K}{2} - \gamma \right) \tilde R - \frac{K}{2} \tilde R^3, \\
 \dot{\tilde \Phi} &= \omega_0,
\end{align}
\end{subequations}
with initial conditions $(\tilde R(0), \tilde \Phi(0)) = (1, 0)$, which directly simulates the low-dimensional representation of the $M$-dimensional state vector.

The goal of this example is to infer the parameters $(K, \omega_0, \gamma)$ based on synthetic data, generated by simulating a system of $M=256$ oscillators with random angular velocities $\omega_i$ over $t \in (0, 30]$.
We record the trajectories $\obs R(t)$ and $\obs \Phi(t)$ of the magnitude and phase of the Kuramoto parameter.
The parameter values used to generate these data are $(K=2,~\omega_0 = \pi/3,~\gamma=0.1)$.
The likelihood of the observed data under the model in \Cref{eq:Kuramoto_hi} with stochastic parameters $\omega_i \sim \mathrm{Cauchy}(\omega_0, \gamma)$ is unavailable, and we must therefore resort to ABC inference, requiring repeated simulation.

\begin{figure}
\centering
\begin{subfigure}[b]{0.48\textwidth}
 \includegraphics[width=\textwidth]{exampletraj_R}
\end{subfigure}
~
\begin{subfigure}[b]{0.48\textwidth}
 \includegraphics[width=\textwidth]{exampletraj_Phi}
\end{subfigure}
\caption{
In colour are five trajectories for $R(t)$ and $\Phi(t)$ for the high-fidelity model in \Cref{eq:Kuramoto_hi}. Stochasticity arises from sampling $\omega_i \sim \mathrm{Cauchy}(\omega_0, \gamma)$ for $i = 1,\dots, 256$. 
In black is the deterministic trajectory from the low-fidelity model in \Cref{eq:Kuramoto_lo}.
All simulations were completed using parameters $K=2$, $\omega_0 = \pi/3$ and $\gamma=0.1$.
Note that the phase plot ``unwraps'' the trajectories of $\Phi(t) = \arg(Z_1(t))$ to avoid $2\pi$-discontinuities. 
}
\label{fig:eg_dynamics}
\end{figure}

Example trajectories of the high-fidelity and low-fidelity models in \Cref{eq:Kuramoto_hi,eq:Kuramoto_lo} are given in \Cref{fig:eg_dynamics}.
The trajectories $\obs R(t)$, $\obs \Phi(t)$, $R(t)$, $\Phi(t)$, $\tilde R(t)$ and $\tilde \Phi(t)$ on $t \in [0,30]$ are infinite dimensional.
In order to easily compare trajectories, we will select a finite number of informative \emph{summary statistics} from the trajectories, guided by the approximated system in \Cref{eq:Kuramoto_lo}.
We take
\begin{align*}
S_1(R, \Phi) &= \left( \frac{1}{30} \int_0^{30} R(t) ~\mathrm dt \right)^2, \\
S_2(R, \Phi) &= \frac{1}{30} \left( \Phi(30) - \Phi(0) \right), \\
S_3(R, \Phi) &= R \left( T_{1/2} \right),
\end{align*}
where $T_{1/2}$ is the first value of $t \in [0,30]$ for which $\obs R(t)$ is halfway between $\obs R(0)=1$ and its average value $S_1(\obs R, \obs \Phi)^{1/2}$.
Justification for the choice of these summary statistics is given in \Cref{appendix:summary_statistics}.

Simulation of the high-fidelity model produces $y \sim f(\cdot~|~(K, \omega_0, \gamma))$ by: 
(a) generating $\omega_i$, $i=1,\dots,256$, from $\mathrm{Cauchy}(\omega_0, \gamma)$; then 
(b) simulating the ODE system in \Cref{eq:Kuramoto_hi}; then 
(c) computing $y = (S_1(R, \Phi), S_2(R, \Phi), S_3(R, \Phi))$.
Simulation of the low-fidelity model produces $\tilde y \sim \tilde f(\cdot~|~(K, \omega_0, \gamma))$ by: 
(a) simulating the ODE system in \Cref{eq:Kuramoto_lo}; then
(b) computing $\tilde y = (S_1(\tilde R, \tilde \Phi), S_2(\tilde R, \tilde \Phi), S_3(\tilde R, \tilde \Phi))$.
Note that the low-fidelity model is deterministic.
Therefore there is no meaningful definition of a coupling between the fidelities: any simulation $y \sim f(\cdot~|~\tilde y,~(K, \omega_0, \gamma)) = f(\cdot~|~(K, \omega_0, \gamma))$ from the high-fidelity model will be independent of $\tilde y$.
The distances $d(y, \obs y)$ and $d(\tilde y, \obs y)$ are defined according to the weighted Euclidean norm, $d(a,b)^2 = 4(a_1 - b_1)^2 + (a_2 - b_2)^2 + (a_3 - b_3)^2$.

\subsection{Existing ABC algorithms}
\label{s:existing}

We set independent uniform priors on $[1, 3]$, $[-2\pi, 2\pi]$ and $[0, 1]$ for $K$, $\omega_0$ and $\gamma$, respectively.
Samples from the ABC posterior, $p_{0.5}((K, \omega_0, \gamma) ~|~\obs y)$, are produced using \Cref{ABC:Rejection} (ABC-RS), \Cref{ABC:SMC} (ABC-SMC), and \Cref{MFABC:Rejection} (MF-ABC-RS) with $\epsilon = 0.5$.
The samples are depicted in \Cref{post:ABC:Rejection,post:ABC:SMC,post:MFABC:Rejection}.
The continuation probability used in \Cref{MFABC:Rejection} (MF-ABC-RS) is the constant $\alpha \equiv 0.5$.
\Cref{table:ABCFlavours} shows observed values for the performance of each of these algorithms, quantified in terms of ESS, simulation time, and observed efficiency (i.e. the ratio of the first two).
Note that the ESS of the sample from \Cref{ABC:SMC} (ABC-SMC) depends on only $N_4 = 1500$ weights, $w_n^{(4)}$, corresponding to the final generation.
However, we will measure the observed efficiency by using the total time to simulate, which includes the total simulation time of the preceding generations.

\begin{table}
\caption{Comparing existing ABC algorithms for sampling $p_{0.5}((K, \omega_0, \gamma)~|~\obs y)$ based on a uniform prior, using $\epsilon=0.5$. 
The stopping condition for \Cref{ABC:Rejection,MFABC:Rejection} is $N=6000$.
The threshold schedule for \Cref{ABC:SMC} was $(2, 1.5, 1, 0.5)$, with stopping conditions $S_t$ of $N_t = 1500$ simulations in each generation $t=1,2,3,4$, leading to the same total number of parameter proposals as in \Cref{ABC:Rejection,MFABC:Rejection}. 
The perturbation kernels $K_t$ in \Cref{ABC:SMC} are Gaussian with diagonal covariance equal to twice the empirical variance of the sample at generation $t$~\cite{Beaumont2009}. 
The continuation probability used in \Cref{MFABC:Rejection} is fixed at the constant $\alpha \equiv 0.5$.
Percentages refer to the increase in efficiency over the base efficiency of ABC-RS.}
\label{table:ABCFlavours}
\center
\begin{tabular}{l|lll}
 & ESS & Sim. time (min) & Efficiency (ESS/min)
\\ \hline \Cref{ABC:Rejection} (ABC-RS) & 148.0 & 43.6 & 3.39
\\ \Cref{ABC:SMC} (ABC-SMC) & 255.1 & 48.8 & 5.23 ($\uparrow 54\%$)
\\ \Cref{MFABC:Rejection} (MF-ABC-RS) & 126.4 & 22.9 & 5.52 ($\uparrow 63\%$)
\end{tabular}
\end{table}

Even with minimal tuning of \Cref{MFABC:Rejection,ABC:SMC}, the samples built using these algorithms both show significant improvements in efficiency.
We have chosen stopping conditions to ensure equal number of parameter proposals for each sample, which demonstrates the distinct effects of each algorithm.
\Cref{ABC:SMC} (ABC-SMC) produces a larger ESS for a similar simulation time.
This is characteristic of ABC-SMC, whereby parameters with low likelihood are less likely to be proposed.
However, \Cref{MFABC:Rejection} (MF-ABC-RS) instead vastly speeds up the simulation time of the fixed number of parameter proposals, albeit with some damage to the ESS.
This result illustrates the orthogonal effects of the SMC and multifidelity ABC algorithms, and thus the potential for combining the techniques in \Cref{MFABC:SMC} to produce further gains in efficiency.

\subsection{Multifidelity ABC-SMC}
\label{s:Results}

In order to demonstrate the increase in efficiency of introducing multifidelity approaches to ABC-SMC, we produced $100$ samples from $p_{0.1}((K, \omega_0, \gamma)~|~\obs y)$, consisting of $50$ replicates from each of \Cref{ABC:SMC} (ABC-SMC) and \Cref{MFABC:SMC} (MF-ABC-SMC).
Common to both algorithms is the number of generations, $T=8$, which corresponds to the nested sequence of ABC neighbourhoods $\Omega_{\epsilon_t}$ with the sequence of thresholds 2.0, 1.5, 1.0, 0.8, 0.6, 0.4, 0.2 and 0.1.
Each generation has a stopping condition of $\mathrm{ESS} \geq 400$, evaluated after every $100$ parameter proposals (to allow for parallelisation).
This condition reflects a specification that we need each generation's sample to be, in some sense, `good enough' to produce a reliable importance distribution that can be used in the next generation.
Finally, we specified the perturbation kernels $K_t(\cdot~|~(K, \omega_0, \gamma)^{(t)}_n)$ at each generation to be Gaussians centred on the parameter value $(K, \omega_0, \gamma)^{(t)}_n$.
The covariance matrices are diagonal matrices $\mathrm{diag}(\sigma_K^{(t)}, \sigma_{\omega_0}^{(t)}, \sigma_\gamma^{(t)})$, where 
\begin{align*}
(\sigma_K^{(t)})^2 &= 2 \frac{\sum w_n^{(t)} (K_n^{(t)} - \mu_K^{(t)})^2}{\sum w_n^{(t)}}, \\
\mu_K^{(t)} &= \frac{\sum w_n^{(t)} K_n^{(t)} }{\sum w_n^{(t)}},
\end{align*}
and similarly for $\sigma_{\omega_0}^{(t)}$ and $\sigma_\gamma^{(t)}$.
These perturbation kernels implement a typical choice for the covariance of using twice the empirical variance of the observed parameter values~\cite{Beaumont2009,Filippi2013}.
Note that we use this definition for the multifidelity case also, where there may be $w^{(t)}_n<0$.
This is almost certainly suboptimal, but we will defer an investigation of the best choice of perturbation kernels for future work.

Further to these common inputs, the parameters $\delta$, $\rho_1$ and $\rho_2$ are the only additional algorithm parameters we need to specify to implement \Cref{MFABC:SMC} (MF-ABC-SMC).
We set lower bounds of $\rho_1 = \rho_2 = 0.01$ on the allowed continuation probabilities, and define the defensive importance sampling parameter, $\delta = 0.01$, for use in \Cref{eq:DefensiveImportance}.
This choice of $\delta$ ensures that the ratio $\pi(\theta)/r(\theta)$ of prior to importance distribution is bounded above by $100$.
Together with the chosen values of $\rho_1$ and $\rho_2$, this ensures that the multifidelity weight in \Cref{eq:qw_mf} is bounded such that $|w_n| \leq 10^4$.
These choices aim to limit the variability of $|w_n|$ to prevent the collapse of the ESS.

\subsubsection{Multifidelity ABC-SMC increases observed efficiency}
\label{s:Results:Efficiency}

\Cref{ABC:SMC,MFABC:SMC} were implemented and run using Julia 1.0.2 on a 36 core CPU (2 $\times$ 18 core with hyperthreading), 2.3/3.7 GHz, 768 GB RAM.
On average across $50$ replicates, the average total simulation time of \Cref{ABC:SMC} (ABC-SMC) was $1.59~\mathrm{h}$. 
In contrast, \Cref{MFABC:SMC} (MF-ABC-SMC) required $0.66~\mathrm{h}$ of total simulation time, which is a reduction of $58\%$.
The observed standard deviation of the total simulation time is $140~\mathrm{s}$ for ABC-SMC, as opposed to $122~\mathrm{s}$ for MF-ABC-SMC.
Thus, the coefficient of variation for simulation time is $.024$ for ABC-SMC, against $0.051$ for MF-ABC-SMC.
Therefore, while the mean simulation time is significantly less for \Cref{MFABC:SMC} (MF-ABC-SMC), the coefficient of variation in the total simulation time is larger.

\Cref{fig:efficiencies_smc} shows the distributions of the observed efficiencies for the $50$ replicates of each of \Cref{ABC:SMC,MFABC:SMC}.
Note that we are defining the observed efficiency as the ratio of the ESS of $\{(K, \omega_0, \gamma)_n^{(8)},  w_n^{(8)} \}$ to the total simulation time (summed across all eight generations).
Clearly, \Cref{MFABC:SMC} (MF-ABC-SMC) produces samples much more efficiently than \Cref{ABC:SMC} (ABC-SMC).
Since the final generation has a stopping condition where the effective sample size reaches $400$ in both algorithms, the difference in the observed efficiency, $\mathrm{ESS}/T_{\mathrm{total}}$, results from the observed differences in simulation time between the two algorithms.


\begin{figure}
\centering
\includegraphics[width=0.95\columnwidth]{efficiencies_smc}
\caption{
Observed efficiencies of generating samples from $p_{0.1}((K, \omega_0, \gamma)~|~\obs y)$ using 50 independent replicates each of \Cref{ABC:SMC} (ABC-SMC) and \Cref{MFABC:SMC} (MF-ABC-SMC), measured as the ESS of the sample $\{(K, \omega_0, \gamma)_n^{(8)}, w_n^{(8)}\}$ divided by the total simulation time across all eight generations.
}
\label{fig:efficiencies_smc}
\end{figure}

Since the ESS of each replicate of $\{ (K, \omega_0, \gamma)_n^{(8)} w_n^{(8)}  \}$ is approximately equal across both algorithms, we should expect similar predictive power for Monte Carlo estimates, $\bar F$, as defined in \Cref{eq:estimate}.
In \Cref{fig:empirical_means}, we show Monte Carlo estimates of each of $\mathbb E_{p_{0.1}}(K)$, $\mathbb E_{p_{0.1}}(\omega_0)$ and $\mathbb E_{p_{0.1}}(\gamma)$ for the $100$ samples constructed using ABC-SMC and MF-ABC-SMC, where the expectations are under the ABC posterior $p_{0.1}((K, \omega_0, \gamma)~|~\obs y)$.
The positions of each point along the horizontal axis show the distribution in estimate values, while the positions on the vertical axis show the distribution in total simulation time, in hours, for each estimate.
Using \Cref{ABC:SMC} (ABC-SMC), the observed means and standard deviations of each estimate are: 
$(2.17, 0.028)$ for $K$, $(1.06, 0.0035)$ for $\omega_0$, and $(0.12, 0.0028)$ for $\gamma$.
This compares to \Cref{MFABC:SMC} (MF-ABC-SMC), where the observed means and standard deviations of each estimate are: 
$(2.16, 0.031)$ for $K$, $(1.06, 0.0035)$ for $\omega_0$, and $(0.12, 0.0031)$ for $\gamma$.
The two algorithms therefore achieve similar accuracy in their estimates of each of the posterior means, but the multifidelity approach achieves this level of accuracy with much less overall simulation time.
Note that, in addition to the analysis of the posterior means, we have also depicted representative posterior samples from each algorithm in \Cref{post:ABC:SMC:ESS400,post:MFABC:SMC:ESS400}.

\begin{figure*}
\centering
\includegraphics[width=\textwidth]{estimates_gen8}
\caption{
The empirical posterior means of each of $K$, $\omega_0$ and $\gamma$ for each of the 100 samples, plotted against the total simulation time required to generate each mean.
}
\label{fig:empirical_means}
\end{figure*}

\subsubsection{MF-ABC-SMC is more effective in early generations}
\label{s:Results:Generations} 

In producing the results in \Cref{fig:empirical_means,fig:efficiencies_smc}, we enforced the same decreasing schedule of $\epsilon_t$ and the same stopping criteria ($\mathrm{ESS} \geq 400$) for all runs of both ABC-SMC and MF-ABC-SMC.
This allows a direct comparison between the two algorithms of the efficiencies at each generation.
\Cref{fig:efficiencies_generation} shows that the sequence of $\epsilon_t$ decreases at such a rate that the efficiency of ABC-SMC remains broadly similar between generations.
However, by using MF-ABC-SMC, the efficiency at all generations $t>1$ (after the first generation) is greater.
Nevertheless, the relative improvement from using MF-ABC-SMC over ABC-SMC begins to diminish as $\epsilon_t$ decreases towards zero.
Hence, the benefit of MF-ABC-SMC appears to accrue most significantly in the earlier generations.

\begin{figure}
\centering
\includegraphics[width=0.95\columnwidth]{eff_per_gen}
\caption{
Observed efficiencies of generating samples from $p_{\epsilon_t}((K, \omega_0, \gamma)~|~\obs y)$ at each generation, measured as the ESS of that generation's sample divided by the total simulation time for that generation.
Note that the vertical axis is on a logarithmic scale.
}
\label{fig:efficiencies_generation}
\end{figure}

\Cref{fig:etas} shows how, as the generation $t$ progresses towards the final generation, $T=8$, the optimal continuation probabilities evolve.
Values in the bottom-left of the figure correspond to smaller continuation probabilities, and thus smaller total simulation times.
At $t=8$, the optimal continuation probabilities are no longer clustered to the bottom-left of the figure, but instead have begun to migrate to the $(1,1)$ corner, which corresponds to the classical ABC-SMC approach.
This means that the overall simulation time of generation $t=8$ will increase relative to earlier generations, as more high-fidelity simulations are required.
It appears that the $\eta_1$ parameter increases quicker than $\eta_2$.
This implies that, in the later generations, any $\tilde y \in \Omega_{\epsilon_t}$ should be `checked' by also simulating $y$ with high probability, whereas we can allow $\tilde y \notin \Omega_{\epsilon_t}$ to go `unchecked' more often.

\begin{figure}
\centering
\includegraphics[width=0.95\columnwidth]{etas_gen}
\caption{
Estimated values of the optimal continuation probabilities $\alpha = \eta_1 \mathbb I(\tilde y \in \Omega_{\epsilon_t}) + \eta_2 \mathbb I(\tilde y \notin \Omega_{\epsilon_t})$ used to produce the multifidelity sample for each of the 50 replicates of generations 2, 4, 6 and 8.
}
\label{fig:etas}
\end{figure}

The primary reason for observing these differences between early and late generations can be justified by the expressions in \Cref{eq:etastar:unbounded,eq:etastar:boundary} specifying the optimal continuation probabilities.
In particular, as $\epsilon_t$ decreases, the value of $W - \fp{W} - \fn{W}$ for each generation also decreases.
Since this quantity is found in the denominators in \Cref{eq:etastar:unbounded,eq:etastar:boundary}, smaller values of $\epsilon$ therefore tend to result in larger values of $\eta_1^\star$ and $\eta_2^\star$.
This can be interpreted as accounting for the larger cost to the ESS of an observed false positive or false negative whenever the overall acceptance rates are small.

\subsubsection{MF-ABC-SMC reduces bias from the ABC approximation}
\label{s:Adaptive}

\Cref{MFABC:SMC} requires a decreasing sequence of $\epsilon_t$ values to be pre-specified.
Often, appropriate values of $\epsilon_t$ cannot be specified before any simulations have been generated.
If the sequence of $\epsilon_t$ decreases too slowly then the algorithm will take a long time to reach the target posterior; too quickly, and each generation will take a long time to produce (or be a poor approximation, for a fixed computational budget).
As a result, rather than specifying a sequence of thresholds \emph{a priori}, previous work~\cite{DelMoral2012} has suggested choosing $\epsilon_{t+1}$ based on a prediction of the ESS for the next generation.
Similarly to this approach, we can use the efficiency, $\psi$, given in \Cref{lemma:phi}, to adaptively produce a decreasing sequence of $\epsilon_t$.
In practice, we work with the approximation to $\psi$ found by using the estimates in \Cref{eq:MonteCarlo} in place of the coefficients in \Cref{eq:PhiComponents}.

\begin{figure}
\centering
\begin{subfigure}[b]{0.48\textwidth}
 \includegraphics[width=\textwidth]{adaptive_epsilon}
 \caption{Adaptive ABC-SMC.}
 \label{fig:adaptive_epsilon}
\end{subfigure}
~
\begin{subfigure}[b]{0.48\textwidth}
 \includegraphics[width=\textwidth]{adaptive_epsilon_eta}
 \caption{Adaptive MF-ABC-SMC.}
 \label{fig:adaptive_epsilon_eta}
\end{subfigure}
\caption{
Adaptively selecting $\epsilon_t$ to achieve a predicted target efficiency equal to the efficiency of the first generation. 
Solid curves estimate the theoretical efficiency $\psi(\epsilon)$ for (a) importance distributions $\hat q_t$, and (b) importance distributions $\hat r_t$ and associated optimised continuation probabilities.
Dotted curves correspond to intermediate optimisations.
Stars plot observed efficiencies, $\mathrm{ESS}/T_{\mathrm{tot}}$, against the selected value of $\epsilon_t$ for samples built using (a) importance distributions $\hat q_t$, and (b) importance distributions $\hat r_t$ and associated optimised continuation probabilities.
}
\label{fig:adaptive}
\end{figure}

In \Cref{fig:adaptive_epsilon} we show one strategy for choosing $\epsilon_{t+1}$ conditionally on generation $t$ in ABC-SMC.
Suppose we are given the sample $\{ \theta_n^{(t)}, w_n^{(t)} \}$ at generation $t$.
Let $\hat q_{t+1}$ be the importance distribution constructed from this sample, as defined in \Cref{eq:importance}.
The approach to choosing $\epsilon_{t+1}$ is to consider the Monte Carlo estimates in \Cref{eq:MonteCarlo}, using the fixed importance distribution $\hat q_{t+1}$, as functions of $\epsilon$.
These estimates produces a predictive estimate of how the efficiency, $\psi(\epsilon) \approx \hat Z^2 / \hat \phi(1,1)$, of using \Cref{ABC:Importance} to produce the sample at generation $t+1$ varies as a function of the threshold, $\epsilon$.
The first generation is produced, with $\hat q_1 = \pi$ and using the predetermined value $\epsilon_1 = 2$.
For each subsequent generation, we then select $\epsilon_{t+1}$ such that the predicted efficiency at generation $t+1$ is equal to the observed efficiency at generation $1$.
\Cref{fig:adaptive_epsilon} demonstrates this procedure implemented for four generations, producing a decreasing sequence of $\epsilon_t$ of $2 > 1.23 > 0.89 > 0.55$.

\Cref{fig:adaptive_epsilon_eta} demonstrates an adaptation of this procedure for application to \Cref{MFABC:SMC} (MF-ABC-SMC), where each generation is produced by a run of \Cref{MFABC:Importance} (MF-ABC-IS).
We choose $\epsilon_{t+1}$ and $\alpha_{t+1}$ by repeatedly alternating between two steps.
First, we construct $\hat r_{t+1}$ from the sample $\{ \theta_n^{(t)}, w_n^{(t)} \}$ from generation $t$, and initialise $\epsilon_{t+1} = \epsilon_t$.
Then we find $(\eta_1^\star, \eta_2^\star)$ by maximising $\psi(\eta_1,\eta_2;~\epsilon_{t+1})$.
This maximisation can be carried out according to \Cref{etastar}, using the estimates in \Cref{eq:MonteCarlo} with $\epsilon_{t+1}$ and $\hat r_{t+1}$ as the threshold and importance distribution, respectively.
The resulting predictive estimate of the efficiency, $\psi(\epsilon;~\eta_1^\star, \eta_2^\star)$, can then be re-interpreted as a function of $\epsilon$, similarly to the ABC-SMC case.
We then decrease $\epsilon_{t+1}$ to the value of $\epsilon$ such that $\psi(\epsilon;~\eta_1^\star,\eta_2^\star)$ is equal to the observed efficiency at generation $t=1$.
We can now re-optimise the continuation probabilities for the new $\epsilon_{t+1}$, and then (if possible) decrease $\epsilon_{t+1}$ further with the new continuation probabilities, continuing to alternate until $\epsilon_{t+1}$ is no longer decreasing.
At this point, generation $t+1$ can be sampled and $\hat r_{t+2}$ constructed.
\Cref{fig:adaptive} shows that the resulting sequence of $\epsilon_t$ is $2 > 0.45 > 0.14 > 0.09$.
Hence, the sequence of $\epsilon_t$ arising from adaptive MF-ABC-SMC decreases much more quickly than the equivalent sequence for ABC-SMC.

In our example, each generation has a stopping condition of $\mathrm{ESS} \geq 400$.
As a result, by choosing to specify a constant target efficiency equal to the observed efficiency of generation $t=1$, we effectively impose a constant target simulation budget for each generation.
Since (for the example in \Cref{fig:adaptive}) we have specified four generations for each run of the adaptive versions of \Cref{ABC:SMC,MFABC:SMC}, we have thus specified a fixed, equal total simulation time for each algorithm.
In this setting, the results in \Cref{fig:adaptive} show that the bias incurred by using an ABC approximation to the posterior with threshold $\epsilon>0$ is vastly reduced by implementing the multifidelity approach to SMC.
Using MF-ABC-SMC, the sample produced in generation $4$ uses an ABC threshold of $\epsilon_4 = 0.09$, giving a sample from $p_{0.09}(\theta~|~\obs y)$.
This threshold is much lower than $\epsilon_4 = 0.55$ used in generation $4$ of ABC-SMC, which gives a sample from $p_{0.55}(\theta~|~\obs y)$.
The posterior samples from each algorithm can be compared in \Cref{post:ABC:SMC:adaptive,post:MFABC:SMC:adaptive}.
Thus, by incorporating the multifidelity approach into a method for adaptively selecting ABC thresholds, we can afford to allow the sequence $\epsilon_t$ of MF-ABC-SMC thresholds to decrease much more rapidly, at no cost to the efficiency of the algorithm.

\section{Discussion and conclusions}
\label{s:Discussion}

In this work we have examined how to integrate two approaches to overcoming the computational bottleneck of repeated simulation within ABC: 
the SMC technique for producing parameter proposals,
and the multifidelity technique for using low-fidelity models to reduce overall simulation time.
By combining these approaches, we have produced the MF-ABC-SMC algorithm in \Cref{MFABC:SMC}.
The results in \Cref{s:Example} demonstrate that the efficiency of sampling from the ABC posterior (measured as the ratio of the ESS to simulation time) can be significantly improved by using \Cref{MFABC:SMC} (MF-ABC-SMC) in place of \Cref{ABC:SMC} (ABC-SMC).
The increase in efficiency is most significant during the early SMC generations, where the acceptance rate is relatively large.
Furthermore, for a fixed computational budget, the bias incurred by using an ABC approximation to the posterior is greatly reduced by modifying \Cref{MFABC:SMC} (MF-ABC-SMC) to implement an adaptive choice of thresholds.

Having introduced the combination of multifidelity and SMC approaches to ABC, a number of open questions emerge.
Some of these questions are specific to the implementation of multifidelity approaches.
However, others arise from a re-evaluation of SMC implementation strategies in this new context.
Below, we consider these two classes of question in turn.

\subsection{Multifidelity implementation}

The key to maximising the benefit of MF-ABC-SMC is the ability to set a continuation probability based on the simulations generated during preceding generations.
The estimates in \Cref{eq:MonteCarlo} of the quantities in \Cref{eq:PhiComponents} are natural Monte Carlo approximations to the required integrals.
In the SMC context, when generating the continuation probability for generation $t+1$, each of these estimates could actually be constructed using the parameter proposals, importance weights, simulations, distances, and continuation probabilities of \emph{any} generation $1 \leq s \leq t$, not just generation $t$.

Specifically, suppose that we denote $Z_{t+1}$ the target quantity in \Cref{eq:Z} for the ABC threshold $\epsilon_{t+1}$ and importance distribution $\hat r_{t+1}$.
Similarly, we denote $\hat Z_{s, t+1}$ the estimates calculated in \Cref{eq:Zhat}, using the ABC threshold $\epsilon_{t+1}$ and importance distribution $\hat r_{t+1}$, and with the distances, importance weights, parameter values and continuation probabilities derived from the sample built at generation $s \leq t$.
Each of the values $\hat Z_{s, t+1}$ is, up to a constant of proportionality, a Monte Carlo estimate of $Z_{t+1}$.
Furthermore, any convex combination $\sum_{s=1}^{t} \mu_{s, t+1} \hat Z_{s, t+1}$ is also a Monte Carlo estimate of $Z_{t+1}$, again up to a multiplicative constant.
This argument and notation applies for every target integral and its corresponding estimate in \Cref{eq:PhiComponents,eq:MonteCarlo}, respectively.
As result of using all preceding generations to estimate $Z_{t+1}$ and the other components in \Cref{eq:PhiComponents}, there may be significant improvements in the reliability of these estimates.
Future work may need to clarify how best to combine many generations with an appropriate choice of the weights $\mu_{s,t+1}$, and the potential for improvement that might arise from this.


Another question arises when we break the assumption made at the start of \Cref{s:MFABC}, and no longer assume that the output spaces of each model fidelity are such that $\tilde{\mathcal Y} = \mathcal Y$.
In general, the observed data, $\obs{\tilde y} \neq \obs y$, the distance metrics, $\tilde d(\tilde y, \obs{\tilde y}) \neq d(y,\obs y)$, and the thresholds, $\tilde \epsilon \neq \epsilon$, may all be distinct.
In this case, any estimate, $\tilde w$, of $\mathbb I(y \in \Omega_\epsilon)$ can be used in place of $\mathbb I(\tilde y \in \Omega_\epsilon)$ to give a multifidelity acceptance weight of the form
\[
 w(\theta, \tilde y, u, y) = \tilde w(\tilde y, \theta) + \frac{\mathbb I(u<\alpha(\tilde y, \theta))}{\alpha(\tilde y, \theta)} \left( \mathbb I(y \in \Omega_\epsilon) - \tilde w(\tilde y, \theta) \right).
\]
Note that, in the case of equal output spaces, we might consider using $\tilde w(y_n) = \mathbb I(\tilde y \in \Omega_{\tilde \epsilon})$ for distinct thresholds, $\tilde \epsilon \neq \epsilon$.
However, in general, $\tilde w(\theta, \tilde y)$ may also encompass completely different output spaces based on distinct modelling frameworks for the same system (albeit with the same parameter space).
In a similar way to evolving acceptance probabilities across generations, we could also evolve the estimate $\tilde w$ across generations, using the information gathered from repeated simulation of both high-fidelity and low-fidelity models to better approximate $\mathbb I(y \in \Omega_\epsilon)$ and thus reduce our reliance on the high-fidelity model.

Finally, as has been noted in previous work on multifidelity ABC~\cite{Prescott2020}, there is much potential in being able to use multiple low-fidelity models, beyond a single low-fidelity approximation.
If there exist multiple low-fidelity models, different generations of MF-ABC-SMC may allow us to progressively focus on using the most efficient model, and identify the specific regions of parameter space for which one model or another may bring most benefit for parameter estimation.

\subsection{SMC implementation}

Previous research into the implementation of ABC-SMC has focussed on ensuring that the importance distribution formed from the preceding generation, as given in \Cref{eq:importance}, is optimal, by choice of the perturbation kernels, $K_t$~\cite{Filippi2013}. 
This has typically been treated as a requirement to trade-off a wide exploration of parameter space against a high acceptance rate.
We have replaced the acceptance rate by the theoretical efficiency as the quantification of an ABC algorithm's performance.
Therefore, since we now explicitly include the simulation time in the definition of the algorithm's performance, the perturbation kernels that optimise the tradeoff between efficiency and exploration may be reformulated and hence different optima used.

Recall the sampling procedure described in \Cref{NegativeResample} for importance distributions constructed from a Monte Carlo sample built using \Cref{MFABC:Importance}.
This procedure applies a perturbation kernel $K(\cdot~|~\theta_n)$ to the values of $\theta_n$, including those with weights $w_n < 0$.
In \Cref{s:Example} we applied a widely-used strategy for determining the perturbation kernels \cite{Beaumont2009}.
This strategy has been justified only in the context of positive weights.
Negative weights potentially make this choice of perturbation kernels suboptimal.
It remains to extend existing results on the optimality of perturbation kernels, such as those in \cite{Filippi2013}, to apply to perturbations of those parameter values with negative weights. 
There is therefore a broad scope for reopening the question of specifying optimal perturbation kernels for SMC, in the context of both including simulation time in the performance tradeoff and for dealing with multifidelity samples with negative weights.

In \Cref{s:Adaptive} we described how to adapt \Cref{ABC:SMC,MFABC:SMC} to implement an adaptive sequence of $\epsilon_t$ as an approach to minimising bias for a fixed computational budget.
The strategy we used was to choose each $\epsilon_t$ as small as possible, while maintaining an efficiency as close as possible to a target, set to equal the observed efficiency of the first generation.
Further work in this area should investigate the use of more sophisticated strategies for choosing each $\epsilon_t$.
This question relates closely to the sequence of stopping criteria.
In \Cref{s:Results}, we constrained the effective sample size at each generation to be at least $400$ to ensure a relatively low variance in each generation's sample, but this choice was made arbitrarily.
Future work should therefore consider how to best achieve the ultimate goal of the SMC algorithm: a sample with minimal bias relative to the true posterior, with a small variance, and constructed quickly.
This goal should be achieved through the interdependent choices of stopping criteria, ABC thresholds, continuation probabilities and perturbation kernels.

\bibliographystyle{IEEEtran}
\bibliography{../../../refs/library}

\clearpage
\pagebreak
\appendix

\renewcommand\thefigure{S.\arabic{figure}}
\setcounter{figure}{0}

\section{Choice of summary statistics}
\label{appendix:summary_statistics}

Recall the summary statistics
\begin{align*}
S_1(R, \Phi) &= \left( \frac{1}{30} \int_0^{30} R(t) ~\mathrm dt \right)^2, \\
S_2(R, \Phi) &= \frac{1}{30} \left( \Phi(30) - \Phi(0) \right), \\
S_3(R, \Phi) &= R \left( T_{1/2} \right),
\end{align*}
where $T_{1/2}$ is the first value of $t \in [0,30]$ for which $\obs R(t)$ is halfway between $\obs R(0)=1$ and its average value $S_1(\obs R, \obs \Phi)^{1/2}$.
These statistics are connected to trajectories,$\phi_j(t)$ for $j =1,\dots,256$, of the high-fidelity model, \Cref{eq:Kuramoto_hi}, through the definition
\[
R(t) \exp (i \Phi(t)) = \frac{1}{256} \sum_{j=1}^{256} \exp(i \phi_j(t)).
\]
The low-fidelity model, in \Cref{eq:Kuramoto_lo}, directly models the evolution of $R$ and $\Phi$.
Example trajectories of the low-fidelity and high-fidelity model are shown in \Cref{fig:eg_dynamics}.

We can use the model in \Cref{eq:Kuramoto_lo} to justify the choice of summary statistics.
In particular, the steady-state value of $\tilde R$ is equal to
\[
\tilde R^\star = \left( 1 - 2\frac{\gamma}{K} \right)^{1/2},
\]
while we can write the solution $\tilde \Phi(t) = \omega_0 t$.
Then we use $S_1$ to approximate $(\tilde R^\star)^2 = 1 - 2\gamma/K$ and thus identify the ratio $\gamma/K$.
Similarly, $S_2 = \tilde \Phi(30)/30 = \omega_0$ allows us to directly identify $\omega_0$.
Finally, $S_3$ is a measure of the time-scale of the dynamics.
Trajectories with equal values for $S_1$ (i.e. equal steady states, and thus equal values for $\gamma/K$) can be distinguished by the speed at which they reach their steady state, which we will infer through $S_3$.
Note that the sampling point, $T_{1/2}$, used in $S_3$ is chosen to be relevant to the observed data specifically, and aims to distinguish any simulated trajectories from $\obs R$ and $\obs \Omega$ in particular.
Thus we select $S_3$ to identify the scale of $\gamma$ and $K$.
Hence, we assume that these three summary statistics will be sufficient to identify the parameters.


\section{Posterior samples}
\Cref{post:ABC:Rejection,post:ABC:SMC,post:ABC:SMC:ESS400,post:ABC:SMC:adaptive,post:MFABC:Rejection,post:MFABC:SMC:ESS400,post:MFABC:SMC:adaptive}
show samples from the posterior distributions $p_\epsilon((K, \omega_0, \gamma)~|~\obs y)$ approximating the Bayesian posteriors of the parameters for the Kuramoto oscillator network in \Cref{s:Example}.
The samples have been generated using \Cref{ABC:Rejection} (ABC-RS), \Cref{ABC:SMC} (ABC-SMC), \Cref{MFABC:Rejection} (MF-ABC-RS), and \Cref{MFABC:SMC} (MF-ABC-SMC).

The plots on the diagonal are one-dimensional empirical marginals for each parameter (i.e. weighted histograms).
The plots above the diagonal are all of the two-dimensional empirical marginals for each parameter pair, represented as heat maps.
The axes are discretised for this visualisation by partitioning each parameter's prior support into $B$ bins, where $B$ is the integer nearest to $(2 \times \mathrm{ESS})^{1/2}$.
For example, when $\mathrm{ESS} \approx 400$, each axis is partitioned into $28 \approx \sqrt{800}$ bins across its prior support.
The plots below the diagonal are all of the two-dimensional projections of the Monte Carlo set $\{ \theta_n, w_n \}$, where the weights $w_n$ are represented by colour.
In particular, negative weights are coloured orange and positive weights are purple.
Note that, for simplicity of visualisation, the weights are rescaled (without any loss of generality) to take values between $-1$ and $+1$.

\subsection{Existing ABC algorithms}
The posterior samples in \Cref{post:ABC:Rejection,post:ABC:SMC,post:MFABC:Rejection} from $p_{0.5}((K, \omega_0, \gamma)~|~\obs y)$ are generated by running \Cref{ABC:Rejection,ABC:SMC,MFABC:Rejection} for a fixed total of $N=6000$ parameter proposals and with threshold $\epsilon = 0.5$. 
For \Cref{ABC:SMC}, these proposals are split equally across four generations with decreasing thresholds $\epsilon_t = 2, 1.5, 1, 0.5$. 
The efficiency of generating these posterior samples is discussed in \Cref{s:existing}.

\subsection{Sequential Monte Carlo}
The posterior samples in \Cref{post:ABC:SMC:ESS400,post:MFABC:SMC:ESS400} from $p_{0.1}((K, \omega_0, \gamma)~|~\obs y)$ are generated by running the two SMC algorithms, \Cref{ABC:SMC,MFABC:SMC}, for eight generations with a common schedule of thresholds $\epsilon_t = 2, 1.5, 1, 0.8, 0.6, 0.4, 0.2, 0.1$, and with stopping condition of $\mathrm{ESS}=400$ at each generation.
Each figure is one representative output of the 50 runs of each of \Cref{ABC:SMC,MFABC:SMC} used in \Cref{s:Results}, where the efficiency of generating these posterior samples is discussed.

\subsection{Adaptive epsilon}
The posterior samples in \Cref{post:ABC:SMC:adaptive,post:MFABC:SMC:adaptive} are generated by the extension of the two SMC algorithms, \Cref{ABC:SMC,MFABC:SMC}, to allow for adaptive selection of thresholds $\epsilon$ as discussed in \Cref{s:Adaptive}.
Running the adaptive extensions of each of \Cref{ABC:SMC,MFABC:SMC} for four generations, with a fixed efficiency in each generation and stopping condition $\mathrm{ESS}=400$, produces the posterior samples in \Cref{post:ABC:SMC:adaptive,post:MFABC:SMC:adaptive}, respectively, from $p_{0.55}((K, \omega_0, \gamma)~|~\obs y)$ and $p_{0.09}((K, \omega_0, \gamma)~|~\obs y)$, respectively.

\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_abc_rs}
\caption{
Sample from ABC posterior generated by \Cref{ABC:Rejection}.
}
\label{post:ABC:Rejection}
\end{figure*}

\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_abc_smc}
\caption{
Sample from ABC posterior produced using the final generation of \Cref{ABC:SMC}.
}
\label{post:ABC:SMC}
\end{figure*}

\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_mfabc_rs}
\caption{
Sample from ABC posterior generated by \Cref{MFABC:Rejection}.
}
\label{post:MFABC:Rejection}
\end{figure*}

\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_abc_smc_ESS400}
\caption{
Sample from ABC posterior produced using the final generation of \Cref{ABC:SMC}.
}
\label{post:ABC:SMC:ESS400}
\end{figure*}

\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_mfabc_smc_ESS400}
\caption{
Sample from ABC posterior produced using the final generation of \Cref{MFABC:SMC}.
}
\label{post:MFABC:SMC:ESS400}
\end{figure*}


\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_abc_smc_adaptive}
\caption{
Sample from ABC posterior produced by the final generation of the adaptive modification of \Cref{ABC:SMC}, as described in \Cref{s:Adaptive}.
}
\label{post:ABC:SMC:adaptive}
\end{figure*}

\begin{figure*}[p]
\centering
\includegraphics[width=\textwidth]{posterior_mfabc_smc_adaptive}
\caption{
Sample from ABC posterior produced by the final generation of the adaptive modification of \Cref{MFABC:SMC}, as described in \Cref{s:Adaptive}.
}
\label{post:MFABC:SMC:adaptive}
\end{figure*}


\end{document}
